# Redis

### 缓存数据的处理流程

和cache一样

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309162326395.png" alt="image-20210309162326395" style="zoom:67%;" />

###  为什么需要redis作缓存

从高性能和高并发来说

* **高性能**

	访问内存的速度远大于访问磁盘的速度

	假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。

	那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

* **高并发**

	一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）

> QPS（Query Per Second）：服务器每秒可以执行的查询次数；

 ### redis如何判断数据是否过期

Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。

![image-20210309163056114](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309163056114.png)

### 过期数据删除策略？

常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

### 内存淘汰机制

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中LRU
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中LRU
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### 持久化技术

[Redis(三)：持久化RDB与AOF详解#](https://www.cnblogs.com/cpaulyz/p/14480402.html#redis三：持久化rdb与aof详解)

### 事务

[Redis(四)：事务#](https://www.cnblogs.com/cpaulyz/p/14506464.html#redis四：事务)

### 缓存穿透

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

* **解决方法1：缓存无效key**

	如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

* **解决方法2：布隆过滤器**

	**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**因为多个值可能hash到同一个hashcode上

	https://www.cnblogs.com/ysocean/p/12594982.html

	本质上是bitmap，可用选择多个hash函数

### 缓存雪崩

#### 原因

* **缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。

	举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。

* **有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。** 

	举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。

#### 解决

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

**其他方案**

1. Redis缓存预热，避免冷启动
2. 通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
3. 时间T到达后，cache中的key和value不会被清掉，而只是被标记为过期（逻辑上过期，物理上不过期），然后程序异步去刷新cache。而后续部分读线程在前面的线程刷新cache成功之前，暂时获取cache中旧的value返回。一旦cache刷新成功，后续所有线程就能直接获取cache中新的value。可以看到，这个思路很大程度上减少了排斥锁的使用（虽然并没有完全消除排斥锁）



### 缓存和数据库一致性问题

https://www.cnblogs.com/myf008/p/13367320.html?utm_source=tuicool

1. **先删缓存，再更新数据库**

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316155844132.png" alt="image-20210316155844132" style="zoom: 67%;" />

2. **先更新数据库，再删缓存**

	写操作先更新数据库，更新成功后使缓存失效

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316155932689.png" alt="image-20210316155932689" style="zoom:67%;" />

3. **先更新数据库，再更新缓存**

	写性能就比较低，可能脏写

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316160008939.png" alt="image-20210316160008939" style="zoom:67%;" />

4. **read/write through**

	CPU向cache写入数据时，同时向memory(后端存储)也写一份，使cache和memory的数据保持一致。

5. **写回。在更新数据的时候**

	cpu更新cache时，只是把更新的cache区标记一下，并不同步更新memory(后端存储)。只是在cache区要被新进入的数据取代时，才更新memory(后端存储)