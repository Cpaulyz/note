[TOC]

面试官，你好，我叫陈彦泽，南京大学软件工程专业的本科生，意向岗位是后台开发

大学时间里我主要借助学校课程的推进来积累一些计算机基础知识的积累，因为平时会有很多大作业，所以也会利用课外时间来学习java后端相关的知识。平时也比较喜欢通过博客来记录学习的笔记和踩过的一些坑，也会把代码上传到github上。

在校期间写过一些项目，比如酒店管理系统、问卷系统等，但其实都是自娱自乐的demo，所以我没写在简历上。我挑了三个自我感觉比较有代表性的项目写，其实是3.5个，第一个项目是在hackathon期间想到的idea，在三天内。。。渴望上线，所以参与了。。。第二是os，这个区别于web项目，其实是一个OS内核的增强开发，感觉比较有意思。第三个是一个比赛项目，主要参与是数据层的开发。

另外。我目前的学分绩是4.61排名年级第二，六级是555分，获得过国家奖学金。。。

# 怼项目

## GitWork

这个项目是去年11月的时候我参加微软华东hackathon的项目，当时的主题是hack for efficiency，我就想到在去年疫情的时候我们都在线上上课，当时我们有一门课叫软件工程与计算2，是团队协作开发一个酒店管理系统，我和队友在gitlab上进行协作，当时有一个很大的痛点就是因为是线上的原因，队友交流比较少，很难知道队友的进度，如果使用任务看板之类的软件进行管理的话可能对积极性比较差的队友效果也不是很好，所以有了这个想法做了一个Visual Gitwok的demo。

最开始的想法，对用户来说很简单，只需要在我们的网站上填入github仓库注册就可以了，我们可以通过仓库地址，调用github的api来获取commit信息，并根据我们定义的规则来进行正则表达式的解析

在用户反馈上，我们在注册仓库后会返回一个url，通过阿里云oss，我们后端生成反应项目进度甘特图，并覆盖原图片，所以url可以一直保持最新的状态，从而实现可视化

遇到的困难：

怎么跟踪？

我们最初的想法是有用户请求再懒加载，刷新，但是如果我们希望以图片url形式作为反馈比较难做到。

轮询，每隔一定时间查询一次，这是可以的，但是国内访问github的话很慢，一旦commit信息多了，json非常大，作为demo可以，但是如果堆积很多的话会出问题，而且

jenkins webhook 无token

## ETF

ETF期权实物交割策略管理系统

这个项目主要是一个花旗杯的web项目，属于商赛的项目，是一个demo，我是参与了后端开发，我们要做的事根据商学院同学的需求，进行期权交割套利策略的回测。我们的数据来源是wind客户端，数据的粒度比较小，但是因为网络的原因，从wind的api接口拿到实时数据很不稳定，所以我们利用python把他的数据爬取下来存到我们本地的mysql中，然后使用springboot作为后端框架，mybatis作为持久层框架，搭建了一个restful api的服务

当时我主要负责的就是dao层的书写，遇到的问题就是并发问题，因为以前在写一些自己的小项目的时候很少会关注到这点，然后他是进行回测的话我们提供了一个接口给前端，前端请求接口后我们会进行买入操作。这个买入和股票有点像，有个卖一价、卖二价的之类的，需求是有一个期望价格，如果有卖的更低的就买入，否则不买。这其实是一个简单的读+写的操作，需要先从数据库中select，判断是否有卖家，有的话在update，并insert一条记录。但是在并发的情况下，可能有两个请求几乎同时到达，可能会进行类似的脏读，也就是重复购买。

当时最开始的想法是加synchronized进行同步，但是可能会阻塞。

第二个想法是for update，因为如果select的话是快照读，用for update加锁

但是最后的其实发现可以用一条sql语句来解决，在一个学长的指导下，我们使用了dual表来进行sql

举个例子吧，

```mysql
insert into dept(dname, db_source) select "TEST",DATABASE() from dual where not exists(
  select * from dept where dname = "TEST"
);
```

## OS

### 介绍

这个项目是在学习操作系统的时候做的一个课程项目，是基于一个经典的操作系统实验教材叫《oranges一个操作系统》的实现，里面用了NASM汇编和C/C++语言实现了一个简单的操作系统，并能够在bochs虚拟机上运行

我主要的工作是实现在书中源码的基础上进行一些增强性的开发，比如FAT12文件系统读取、IO、进程调度等，并用自己写的进程调度算法和信号量与PV操作实现了一个读写者问题的并发控制

简单介绍一下各个部分

### FAT12

FAT12是DOS时代的早期文件系统，之所以选择FAT12作为文件系统，很大的原因就是因为FAT12结构非常简单，这里主要是实现了对FAT12文件系统的读取，包括ls、ls -l、cat指令

它分为几个区域

![image-20210314191239297](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210314191239297.png)

引导扇区定义了一些元数据，不重要

FAT1和2是备份的关系，内容一致，是核心，每个FAT

每个FAT表项会指向数据区的一个簇和下一个FAT表项，如果下一个FAT表项为一些特定值的话说明已经结束或者损坏

而根目录区有一些文件名、第一个FAT簇号等信息

所以读取的话比较简单，第一步就是扫描元数据。然后根据元数据，读根目录区，建立起一个文件树，之后如果ls或者cat指令的话，就根据文件树找到文件对应的第一个fat簇号，然后递归读取即可。

遇到了一些难题

* 因为是c和汇编混合编译，里面c调用了汇编写的方法，所以第一个问题就是传参和取参的问题。

	C 中的函数参数被⼊栈，在汇编中根据 esp 计算参数在栈中的位置 

	返回值被放在 eax 中

	![image-20210314193028337](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210314193028337.png)

* 第二个问题是怎么制作FAT文件系统，因为FAT文件系统是一个比较古老的文件系统了，最后在linux下找到一个mkfs.fat的命令，实现方式是先下创建一个新的软盘镜像a.img

	` mkfs.fat -F 12 -C a.img 1440 `

	在当前目录下创建一个新目录(./mount)作为挂载点

	` mkdir mount `

	将镜像./a.img挂载到./mount下

	` sudo mount a.img mount`

### IO

这个的话是修改内核代码，实现了输入输出的功能，比如大小写切换，按Shift+字母会输出大写、定时刷新、ctrl+r搜索，ctrl+z撤销、删除等

这里的话用了书上的源码，所以在实现的时候屏蔽了底层的一些细节，比如进程切换、寻址这类的

实现了tty和console两个类，不同 TTY 各有一个 CONSOLE，各个 CONSOLE 公用同一块显存。

tty记录了输入缓存，console记录了显存和指针

主要实现逻辑是，每个tty也就是中断是一个进程，tty进程循环进行键盘读、屏幕写操作

敲击键盘的时候其实有三类动作和两种编码，分别是按下、保持按下、弹起

Make Code——当一个键被按下或者保持住按下时会产生Make Code

Break Code——当一个键弹起时，产生Break Code

键盘敲击的会把这一些列的code传进tty中一个缓冲区的地方

我实现的内容就是把缓冲区内的code提取出来，进行解析

ctrl+r的话关中断，搜索实现就是把屏幕输出的内容写到一个进程独享的数组中，然后进行匹配

ctrl+z撤销是难点，用的是redo的方法（参考了sql的思想，redo、undo，为什么不用undo？因为还有删除等东西，undo起来很麻烦）

删除的话因为根据我们的习惯，空格删除是空格，tab删除是tab，而在输出的时候，tab=4个空格，所以用了一个小技巧就是把颜色设为不一样

###  并发

实现了最简单的调度算法，时间片轮转

因为读写者问题是说读的时候可以有多个进程读（这里做过设置，比如1、2、3），写的时候只能有一个进程写，所以用的是信号量与PV操作，定义全局的信号量，每个信号量内有一个阻塞队列用于记录进程的PCB

难点在于怎么阻塞进程，这里想到了最简单的办法在PCB上加一个block字段

## 编译原理

flex 正则表达 提取token 词法分析 并输出一些基本的词法错误，比如未定义的词素

bison 让词法分析器返回词法单元，构建语法分析树

语义分析，进行类型检查

中间代码生成，比如为遍历分配空间，参数传递等

转换为中间代码，生成MIPS32指令

* 指令选择
* 寄存器分配
* 栈管理

![image-20210313202705172](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210313202705172.png)

# JAVA数据结构

## Map

### 源码解析

[史上最详细的 JDK 1.8 HashMap 源码解析](https://joonwhee.blog.csdn.net/article/details/78996181)

### 基本信息

```java
// 默认容量16
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; 
 
// 最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;    
// 因为最大的正n次方是 0100000.... 
 
// 默认负载因子0.75
static final float DEFAULT_LOAD_FACTOR = 0.75f; 
 
// 链表节点转换红黑树节点的阈值, 9个节点转
static final int TREEIFY_THRESHOLD = 8; 
 
// 红黑树节点转换链表节点的阈值, 6个节点转
static final int UNTREEIFY_THRESHOLD = 6;   
 
// 转红黑树时, table的最小长度
static final int MIN_TREEIFY_CAPACITY = 64; 
 
// 链表节点, 继承自Entry
static class Node<K,V> implements Map.Entry<K,V> {  
    final int hash;
    final K key;
    V value;
    Node<K,V> next;
 
    // ... ...
}
 
// 红黑树节点
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
   
    // ...
}
```

### 定位桶

```java
static final int hash(Object key) { // 计算key的hash值
    int h;
    // 1.先拿到key的hashCode值; 2.将hashCode的高16位参与运算
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
// 代码2
int n = tab.length;
// 将(tab.length - 1) 与 hash值进行&运算
int index = (n - 1) & hash;
```

1. 拿到 key 的 hashCode 值
2. 将 hashCode 的高位参与运算，重新计算 hash 值
3. 将计算出来的 hash 值与 (table.length - 1) 进行 & 运算

在 JDK1.8 的实现中，还优化了高位运算的算法，将 hashCode 的高 16 位与 hashCode 进行异或运算，主要是为了在 table 的 length 较小的时候，让高位也参与运算，并且不会有太大的开销。

### Get

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
 
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    // 1.对table进行校验：table不为空 && table长度大于0 && 
    // table索引位置(使用table.length - 1和hash值进行位与运算)的节点不为空
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 2.检查first节点的hash值和key是否和入参的一样，如果一样则first即为目标节点，直接返回first节点
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        // 3.如果first不是目标节点，并且first的next节点不为空则继续遍历
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                // 4.如果是红黑树节点，则调用红黑树的查找目标节点方法getTreeNode
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {
                // 5.执行链表节点的查找，向下遍历链表, 直至找到节点的key和入参的key相等时,返回该节点
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    // 6.找不到符合的返回空
    return null;
}
```

如果是红黑树节点，find方法如下

```java
final TreeNode<K,V> getTreeNode(int h, Object k) {
    // 1.首先找到红黑树的根节点；2.使用根节点调用find方法
    return ((parent != null) ? root() : this).find(h, k, null);
}

/**
 * 从调用此方法的节点开始查找, 通过hash值和key找到对应的节点
 * 此方法是红黑树节点的查找, 红黑树是特殊的自平衡二叉查找树
 * 平衡二叉查找树的特点：左节点<根节点<右节点
 */
final TreeNode<K,V> find(int h, Object k, Class<?> kc) {
    // 1.将p节点赋值为调用此方法的节点，即为红黑树根节点
    TreeNode<K,V> p = this;
    // 2.从p节点开始向下遍历
    do {
        int ph, dir; K pk;
        TreeNode<K,V> pl = p.left, pr = p.right, q;
        // 3.如果传入的hash值小于p节点的hash值，则往p节点的左边遍历
        if ((ph = p.hash) > h)
            p = pl;
        else if (ph < h) // 4.如果传入的hash值大于p节点的hash值，则往p节点的右边遍历
            p = pr;
        // 5.如果传入的hash值和key值等于p节点的hash值和key值,则p节点为目标节点,返回p节点
        else if ((pk = p.key) == k || (k != null && k.equals(pk)))
            return p;
        else if (pl == null)    // 6.p节点的左节点为空则将向右遍历
            p = pr;
        else if (pr == null)    // 7.p节点的右节点为空则向左遍历
            p = pl;
        // 8.将p节点与k进行比较
        else if ((kc != null ||
                  (kc = comparableClassFor(k)) != null) && // 8.1 kc不为空代表k实现了Comparable
                 (dir = compareComparables(kc, k, pk)) != 0)// 8.2 k<pk则dir<0, k>pk则dir>0
            // 8.3 k<pk则向左遍历(p赋值为p的左节点), 否则向右遍历
            p = (dir < 0) ? pl : pr;
        // 9.代码走到此处, 代表key所属类没有实现Comparable, 直接指定向p的右边遍历
        else if ((q = pr.find(h, k, kc)) != null) 
            return q;
        // 10.代码走到此处代表“pr.find(h, k, kc)”为空, 因此直接向左遍历
        else
            p = pl;
    } while (p != null);
    return null;
}
```

### Put

put方法内部调用了putVal

1. 如果定位到的数组位置没有元素 就直接插入。
2. 如果定位到的数组位置有元素就和要插入的 key 比较，如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用`e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value)`将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。

![image-20210313202705172](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210313202705172.png)

> - 直接覆盖之后应该就会 return，不会有后续操作。参考 JDK8 HashMap.java 658 行（[issue#608](https://github.com/Snailclimb/JavaGuide/issues/608)）。
> - 当链表长度大于阈值（默认为 8）并且 HashMap 数组长度超过 64 的时候才会执行链表转红黑树的操作，否则就只是对数组扩容。参考 HashMap 的 `treeifyBin()` 方法（[issue#1087](https://github.com/Snailclimb/JavaGuide/issues/1087)）。

### resize

1. 判断原本哈希表的size，如果是0，就说明刚刚初始化，用默认值来初始化。否则判断是否超过最大容量，如果是的话直接返回老表，否则设置新表容量为老表两倍(<<1)，新的阈值为原来两倍

2. 转移节点。如果老表头.next==NULL，说明只有一个节点，直接转移即可。否则判断是红黑树还是链表，分别进行rehash计算

	值得一提的是，这里用了一个很巧妙的操作进行重定位，节点重 hash 为什么只可能分布在 “原索引位置” 与 “原索引 + oldCap 位置”。

	所以只需要把旧节点的hash值与旧容量进行与运算，如果是0那么位置不变，如果不为0，那么新位置为“原索引 + oldCap 位置”

	![image-20210313203711448](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210313203711448.png)

### JDK1.7和JDK1.8下的区别

1. 最重要的一点是底层结构不一样，1.7是数组+链表，1.8则是数组+链表+红黑树结构;

2. jdk1.7中当哈希表为空时，会先调用inflateTable()初始化一个数组；而1.8则是直接调用resize()扩容;

3. 插入键值对的put方法的区别，1.8中会将节点插入到链表尾部，而1.7中是采用头插；

4. 扩容时1.8会保持原链表的顺序，而1.7会颠倒链表的顺序；而且1.8是在元素插入后检测是否需要扩容，1.7则是在元素插入前；

5. 计算 table 初始容量的方式发生了改变，老的方式是从1开始不断向左进行移位运算，直到找到大于等于入参容量的值；新的方式则是通过“5个移位+或等于运算”来计算。

  ```java
  
  // JDK 1.7.0
  public HashMap(int initialCapacity, float loadFactor) {
      // 省略
      // Find a power of 2 >= initialCapacity
      int capacity = 1;
      while (capacity < initialCapacity)
          capacity <<= 1;
      // ... 省略
  }
  // JDK 1.8.0_191
  static final int tableSizeFor(int cap) {
      int n = cap - 1;
      n |= n >>> 1;
      n |= n >>> 2;
      n |= n >>> 4;
      n |= n >>> 8;
      n |= n >>> 16;
      return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
  }
  ```

6. 优化了 hash 值的计算方式，老的通过一顿瞎JB操作，新的只是简单的让高16位参与了运算。

	```java
	// JDK 1.7.0
	static int hash(int h) {
	    h ^= (h >>> 20) ^ (h >>> 12);
	    return h ^ (h >>> 7) ^ (h >>> 4);
	}
	// JDK 1.8.0_191
	static final int hash(Object key) {
	    int h;
	    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
	}
	```

### 为什么说是线程不安全的？

HashMap在并发场景下可能存在以下问题：

1. 死循环
2. 数据丢失

#### 死循环

关于死循环的问题，在Java8中个人认为是不存在了，在Java8之前的版本中之所以出现死循环是因为在resize的过程中对链表进行了倒序处理；在Java8中不再倒序处理，自然也不会出现死循环。

见https://joonwhee.blog.csdn.net/article/details/106324537

简单来说，jdk1.7的时候，底层是链表实现的，rehash的时候采用了头插法，多线程并发下，可能产生循环链表，因为rehash的时候终止条件是node.next==null，所以会死循环

在jdk1.8中，用了loHead/loTai和hiHead/hiTail，保证尾插法

#### 数据丢失

比如jdk1.8，比如在putVal的时候，两个线程都进这个分支的话会数据覆盖，从而造成数据丢失

```java
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
```



### 总结

[面试阿里，HashMap 这一篇就够了](https://joonwhee.blog.csdn.net/article/details/106324537)

插入流程图

![image-20210313214535625](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210313214535625.png)

resize流程图

![image-20210313214608168](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210313214608168.png)

## ConcurrentHashMap

### 1.7

* 概述

ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。

整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为**分段锁**。注意，行文中，我很多地方用了“**槽**”来代表一个 segment。

简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

* 初始化

initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。

loadFactor：负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。

* put

	同map1.7，只是put的时候要会调用 node = tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁

* 扩容

	segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry\<K,V>[] 进行扩容，扩容后，容量为原来的 2 倍。

	首先，我们要回顾一下触发扩容的地方，put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么先进行扩容，再插值，读者这个时候可以回去 put 方法看一眼。

	该方法不需要考虑并发，因为到这里的时候，是持有该 segment 的独占锁的。

### 1.8

结构上和 Java8 的 HashMap 基本上一样，不过它要保证线程安全性，所以在源码上确实要复杂一些

* 扩容

	1、如果新增节点之后，所在链表的元素个数达到了阈值 8，则会调用`treeifyBin`方法把链表转换成红黑树，不过在结构转换之前，会对数组长度进行判断，实现如下：

	如果数组长度n小于阈值`MIN_TREEIFY_CAPACITY`，默认是64，则会调用`tryPresize`方法把数组长度扩大到原来的两倍，并触发`transfer`方法，重新调整节点的位置。

	2、新增节点之后，会调用`addCount`方法记录元素个数，并检查是否需要进行扩容，当数组元素个数达到阈值时，会触发`transfer`方法，重新调整节点的位置。

## List

### ArrayList

[Java集合：ArrayList详解](https://joonwhee.blog.csdn.net/article/details/79190114)

主要注意扩容是1.5倍，默认容量`DEFAULT_CAPACITY = 10`，扩容用到了`Arrays.copyOf`

### LinkedList

[Java集合：LinkedList详解](https://joonwhee.blog.csdn.net/article/details/79247389)

双向链表

# JVM

## 内存

### 介绍下 Java 内存区域（AKA运行时数据区）

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309153224314.png" alt="image-20210309153224314" style="zoom:67%;" />

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309153240177.png" alt="image-20210309153240177" style="zoom:67%;" />

* **堆**

	此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存

	GC发生的区域，分为新生代、老年代，新生代又分为Eden和Survivor区，Survivor区有from区和to区

* **方法区**

	用于存放类似于元数据信息方面的数据的，比如类信息，常量，静态变量，编译后代码···等

	类加载器将 .class 文件搬过来就是先丢到这一块上

* **虚拟机栈**

	代码的运行空间，每个方法执行时会有自己的栈帧，存放局部变量表（各种数据类型boolean、byte、char、short、int、float、long、double、对象引用reference 类型）。方法return或者抛出异常时候，会释放栈空间

	生命周期同线程

* **本地方法栈**

	虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务

* **程序计数器**

	线程独享，两个作用

	1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
	2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

	==唯一不会OOM的区域==

### JDK1.8的变化，怎么理解？

JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。

**JDK1.8 hotspot移除了永久代用元空间(Metaspace)取而代之, 这时候字符串常量池还在堆, 运行时常量池还在方法区, 只不过方法区的实现从永久代变成了元空间(Metaspace)**

1. 整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。

2. 元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 `MaxPermSize` 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。
3. 在 JDK8，合并 HotSpot 和 JRockit 的代码时, JRockit 从来没有一个叫永久代的东西, 合并之后就没有必要额外的设置这么一个永久代的地方了。

### Java 对象的创建过程

![image-20210309154120262](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309154120262.png)

1. **类加载检查**

	虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程

2. **分配内存**

	对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来

3. **初始化零值**

	虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值

4. **设置对象头**

	初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的**元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。**

5. **init**

	构造函数

### 对象头有哪些内容

对象头中包含两部分: MarkWord 和 类型指针.

如果是数组对象的话, 对象头还有一部分是存储数组的长度.

多线程下synchronized的加锁就是对同一个对象的对象头中的MarkWord中的变量进行CAS操作.

* **MarkWord**	

	Mark Word用于存储对象自身的运行时数据, 如HashCode, GC分代年龄, 锁状态标志, 线程持有的锁, 偏向线程ID等等.
	占用内存大小与虚拟机位长一致(32位JVM -> MarkWord是32位, 64位JVM->MarkWord是64位).

	![image-20210310213926968](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210310213926968.png)

* **类型指针**

	类型指针指向对象的类元数据, 虚拟机通过这个指针确定该对象是哪个类的实例.

### 对象创建时内存分配的两种算法

取决于 Java 堆内存是否规整

![image-20210309154819622](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309154819622.png)

1. **指针碰撞法**

	堆内存规整时，可以理解为用过的内存全都在一边，空闲的在另外一边，这样就有一个中间位置，可以用一个指针指向，只要向空间的的内存方向移动指针即可分配内存。类似OS的栈顶指针

	Seiral、ParNew

2. **空闲列表法**

	堆内存不规整时，维护一个列表，记录哪些块可用。分配时从列表中找一个足够大的内存块来分配给示例对象，并更新列表

	CMS

> 并发问题？
>
> 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
- **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

### 对象的访问定位的两种方式

* **句柄**

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309155348376.png" alt="image-20210309155348376" style="zoom: 67%;" />

	Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息

	好处在于，GC的时候只需要更新句柄就可以了

* **直接指针**

	Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址

	![image-20210309155435230](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309155435230.png)

	好处在于，速度快，节省了一次指针定位的时间开销

## GC

> https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6

### 什么需要survivor区

1. 减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代，避免频繁的Full GC
2. 两个survivor区，解决了碎片化的问题（复制算法）

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309092105429.png" alt="image-20210309092105429" style="zoom:67%;" />

### 怎样进入老年代

* **大对象直接进入老年代**

	大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。

	为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

* **长期存活的对象进入老年代**

	每个对象都有一个age计数器

	如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置。

### 如何判断对象死亡

* **引用计数法**

	给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。

	难以解决循环依赖问题

* **可达性分析**

	这个算法的基本思想就是通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

### 可作为 GC Roots 的对象包括下面几种:

- 虚拟机栈(栈帧中的本地变量表)中引用的对象
- 本地方法栈(Native 方法)中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中常量引用的对象
- 所有被同步锁持有的对象

### 垃圾收集器

* **Serial收集器**

	串行，在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束

	**新生代采用标记-复制算法，老年代采用标记-整理算法**

	![image-20210309155709468](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309155709468.png)

* **ParNew收集器**

	Serial的多线程版本

	**新生代采用标记-复制算法，老年代采用标记-整理算法。**


* **Parallel Scavenge算法**

* **CMS**

	回收器是针对老年代垃圾回收，**“标记-清除”算法**实现，会有大量空间碎片

	![image-20210309160024530](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309160024530.png)

	* 初始标记：停止用户线程，记录下直接与 root 相连的对象和年轻代中活着的对象引用到的老年代的对象，找出所有存活的对象
	* 并发标记：因为是并发运行的，在运行期间会发生新生代的对象晋升到老年代、或者是直接在老年代分配对象、或者更新老年代对象的引用关系等等，对于这些对象，都是需要进行重新标记的，否则有些对象就会被遗漏，发生漏标的情况
	* 重新标记：停止用户线程，重新标记的内存范围是整个堆
	* 并发清除(CMS-concurrent-sweep)：与用户线程同时运行；

* **G1**

### 垃圾收集算法

* 标记-清除
* 标记-复制
* 标记-整理

* 分代收集

### 四种引用类型

https://www.cnblogs.com/liyutian/p/9690974.html

## 类加载

### 类加载过程

* **加载**

	1. 将class文件加载到内存
	2. 将静态数据结构转化成方法区中运行时的数据结构
	3. 在堆中生成一个代表这个类的 java.lang.Class对象作为数据访问的入口

* **连接**

	1. 验证：确保加载的类符合 JVM 规范和安全，保证被校验类的方法在运行时不会做出危害虚拟机的事件，其实就是一个安全检查
	2. 准备：为static变量在方法区中分配内存空间，设置变量的初始值，例如 static int a = 3 （注意：准备阶段只设置类中的静态变量（方法区中），不包括实例变量（堆内存中），实例变量是对象初始化时赋值的）
	3. 解析：虚拟机将常量池内的符号引用替换为直接引用的过程（符号引用比如我现在import java.util.ArrayList这就算符号引用，直接引用就是指针或者对象地址，注意引用对象一定是在内存进行）

* **初始化**

	1. 保证执行前父类初始化完毕
	2. 顺序执行所有类变量（static修饰的成员变量）显式初始化和静态代码块中语句

* **卸载**

	GC将无用对象从内存中卸载

### ClassLoader

JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自`java.lang.ClassLoader`：

1. **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由C++实现，负责加载 `%JAVA_HOME%/lib`目录下的jar包和类或者或被 `-Xbootclasspath`参数指定的路径中的所有类。
2. **ExtensionClassLoader(扩展类加载器)** ：主要负责加载目录 `%JRE_HOME%/lib/ext` 目录下的jar包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的jar包。
3. **AppClassLoader(应用程序类加载器)** :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。

### 双亲委派模型

每一个类都有一个对应它的类加载器。系统中的 ClassLoder 在协同工作的时候会默认使用 **双亲委派模型** 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派该父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。

当父类加载器无法处理时，才由自己来处理。当父类加载器为null时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器。

1. Bootstrap ClassLoader启动类加载器：默认会去加载JAVA_HOME/lib目录下的jar
2. Extention ClassLoader扩展类加载器：默认去加载JAVA_HOME/lib/ext目录下的jar
3. Application ClassLoader应用程序类加载器：比如我们的web应用，会加载web程序中ClassPath下的类
4. User ClassLoader用户自定义类加载器：由用户自己定义

![image-20210311211655135](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210311211655135.png)

### 你觉得双亲委派这名字有没有问题？

有

Parent Delegation Model 

其实没有“双”，只有亲

### 为什么需要双亲委派?

1. 防止核心库被随意篡改，比如自己写的string.class不会被加载
2. 避免重复加载，当父ClassLoader已经加载该类的时候，就不需要子ClassLoader在加载一次

# OS

## 谈谈你对OS的理解

从OS发展的角度来看

* 一开始的计算机是没有操作系统的，是手工操作阶段，手工设置操作位，用户独占资源，数据输入、程序执行、结果输出均联机进行，效率低。
* 引入了装入程序，用卡片和纸带来描述，装入→汇编/编译→执行→输出。脱机执行，例如shell脚本
* 再后来出现了批处理，操作员成批输入作业，成批执行作业
* 由于IO和计算速度的差异，引入了多道程序
* 磁盘出现，OS登场

从OS的作用来看

* 计算机系统最基础的系统软件，管理软硬件资源、控制程序执行，改善人机界面
* 包括了进程调度、进程通信、内存管理、设备管理、文件管理、作业控制等

## 有哪些寄存器？

* 用户可见寄存器
	* 数据寄存器（通用寄存器）
	* 地址寄存器（索引、栈地址、段地址等）
		* 页表基址寄存器：只有一个，哪个进程在运行，存的就是哪个
* 控制与状态寄存器
	* 控制寄存器
	* 程序计数器PC
	* 指令寄存器IR
	* 条件码CC
	* 标志位（中断位、中断允许位、中断屏蔽位、处理器模式位、内存保护位...）
* 程序状态字PSW 指记录**当前程序运行的动态信息**，通常包含： 
	* 程序计数器，指令寄存器，条件码 
	* 中断字，中断允许/禁止，中断屏蔽，处理器模式，内存保护、调试控制
	* 可以设置一组控制与状态寄存器、也可专设一个PSW寄存器
	* 例如，x86中，PSW由标志寄存器EFLAGS和指令指针寄存器EIP组成

## 管态和目态？

CPU有两个状态，分别是管态和目态，

* 管态，即操作系统的管理程序运行时的状态，具有较高的特权级别，也称为特权态、系统态、内核态或者核心态。当处理器处于管态时，可以执行所有的指令，包括各种特权指令，也可以使用所有的资源，并且具有改变处理器状态的能力。
* 目态，即用户程序运行时的状态，具有较低的特权级别，又称为普通态或用户态。在这种状态下不能使用特权指令，不能直接使用系统资源，也不能改变CPU的工作状态，并且只能访问这个用户程序自己的存储空间。
* 特权指令：仅在内核态下才能使用的指令，设计改变机器状态、修改寄存器内容、启动设备IO等
	* 如启动IO设备、设置时钟、清空内存、建立存储键、设置中断屏蔽位、修改寄存器值、加载PSW等
* 非特权指令
	* 能被所有程序使用

## 什么是系统调用？实现机制是怎样的？

1. 编写系统调用服务例程
2. 设计系统调用入口地址表（可能还包含参数个数）
3. 陷阱处理机制，需要开辟现场保护区，以保存发生系统调用时应用程序的处理器现场

![image-20210104234130075](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210104234130075.png)

比如说在汇编语言里面，有个 INT n，这里的n就是中断类型码

内存里有一个中断向量表，就是这里的入口地址表，根据n，我们可以找到中断向量，也就是中断处理程序的入口地址，然后进行执行

> 系统调用和中断的关系？
>
> 系统调用是一种中断，OS内核是中断驱动的，中断是激活OS的唯一方式

## 中断的分类

* （狭义）**中断**/**异步中断**：处理器之外的中断事件——又称**外中断**
	* 可屏蔽、不可屏蔽
	* IO中断、时钟中断、外部信号中断
* **异常**：当前运行指令引起的中断，处理器内部的中断信号——**内中断**
	* 地址异常（超出范围）、算术异常、处理器硬件故障...
* 系统异常：执行陷入指令而触发系统调用
	* 请求设备、请求IO、创建进程等

## 中断的实现机制？

中断需要软硬件配置

* 硬件part

	![image-20210105141338464](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105141338464.png)

* 软件part

	同上面系统调用

	* 用户模式到内核模式 
		* 由中断/异常/系统调用中断用户进程 执行而触发 
			1. 处理器模式转为内核模式 
			2. 保存当前进程的PC/PSW值到**核心栈** 
			3. 转向中断/异常/系统调用处理程序
	* 内核模式到用户模式
		* OS执行中断返回指令将控制权交还 用户进程而触发
			1. 从待运行进程核心栈中弹出PSW/PC值 
			2. 处理器模式转为用户模式

	> ![image-20210105141430103](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105141430103.png)

	多中断的情况下也有讲究

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105142556687.png" alt="image-20210105142556687" style="zoom: 50%;" />

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105142623667.png" alt="image-20210105142623667" style="zoom:50%;" />

## 进程是什么？有哪些定义？

* 进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动 
* 进程是操作系统进行资源分配和调度的一个独立单位
* 进程的五个实体部分**（P,C,D,R,PSW）**
	* (OS管理运行程序的)数据结构P 
	* (运行程序的)内存代码C 
	* (运行程序的)内存数据D 
	* (运行程序的)通用寄存器信息R 
	* (OS控制程序执行的)程序状态字信息PSW

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105152602369.png" alt="image-20210105152602369" style="zoom:50%;" />

某一时刻进程的内容及其执行状态集合： 

* 进程**控制块**: 保存进程的标识信息、状态信息和控制信息 
* 进程**程序块:** 进程执行的程序空间 
* 进程**数据块**: 进程处理的数据空间，包括数据、处理函数的用户栈和可修改的程序 
* **核心栈**: 每个进程绑一个，进程在内核态工作时用，保存中断/异常现场，也用于传参、返回地址等。
	* 进程在内核模式下运行时使用的堆栈，中断或系统过程使用进程映像是内存级的物理实体，又称为**进程的内存映像**

## OS怎么感知进程？

通过PCB

系统在创建进程时候建立PCB，进程运行结束才回收，进程借助PCB才能被调度执行

* **标识信息**：唯一标识进程的信息
	* 系统分配的、用户定义的标识号、进程组标识号
* **现场信息**：用于存放该进程运行时的处理器现场信息
* **控制信息**：用于存放与管理、调度进程相关的信息

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105152018329.png" alt="image-20210105152018329" style="zoom:67%;" />

## 怎么理解线程？

传统的进程存在一些问题

存在问题

* 进程切换开销大
* 进程通信开销大
* 限制了进程并发效率
* 降低并行计算效率

通过引入线程，进程的作用变为：

* **独立分配资源**
	* 仍有进程完成，作为系统资源分配和保护的基本单位
* **被调度分派执行**
	* 交给称作“线程”的实体来完成
	* “线程”作为系统调度和分派的基本单位

线程又分为OS感知线程和OS不感知线程

* KLT：OS提供了一个应用 程序设计接口API， 供开发者使用KLT
	* 进程中的一个线程被阻塞了，内核能调度同一进程的其它线程占有处理器运行 
	* 多处理器环境中，内核能同时调度同一进程中多个线程并行执行 
	* 内核级线程数据结构和堆栈小，切换快
	* 线程调度和管理在内核实现，在同一进程中，控制权从一个线程传送到另一个线程时需要“用户态—内核态—用户态”切换，系统开销较大
* ULT
	* 线程管理的所有工作都由应用程序完成，内核没有意识到线程的存在
	* 不能利用多处理器的优点，OS调度进程，仅有一个ULT能执行
	* 一个ULT的阻塞，将引起整个进程的阻塞
* 混合级：有的是ULT，有的是KLT

> JAVA里的线程：混合级
>
> 1、证明java线程不是纯粹用户级线程：在java中起一堆线程，系统可以感知到。从java应用程序中的某个线程阻塞，是不会引起整个进程的阻塞，从这两点看，java线程绝不是纯粹的用户级线程。 （线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程）
>
> 2、再来，证明java线程不是纯粹内核级线程：这点比较直观，如果使用纯粹的内核级线程，那么有关线程的所有管理工作都是内核完成的，用户程序中没有管理线程的代码。显然，java线程库提供了大量的线程管理机制，因此java线程绝不是纯粹的内核级线程。 综上，java线程是混合型的线程模型，一般而言是通过lwp将用户级线程映射到内核线程中。

## 谈谈调度算法？

* 高级调度，又称作业调度、长程调度
	* 挑选作业进入内存，并为其分配所需资源并创建作业对应的用户进程
	* 控制多道程序的道数
* 中级调度，又称平衡负载调度
	* 决定主存中的可用进程集合
	* 内存紧缺时将不能运行的进程换出内存，"挂起"
	* 内存富裕时，重新调回内存
* 低级调度，又称进程调度、短程调度
	* 决定哪个可用进程占用处理器执行

## 调度算法？

* FCFS 先到先服务 非抢占式
* RR 时间片轮转 抢占式
	* 抢占时间：时间片用完
* SPN 最短进程优先 非抢占式
	* 抢占时间：进程到来/结束时，需要预估时间
* SRT 最短剩余时间优先 抢占式
	* 抢占时间：进程到来/结束时，需要预估时间
* HRRN 最高相应比优先 非抢占式
	* highest response ratio next
* feedback 多级反馈队列 抢占式
	* Q：如何照顾低优先级队列？
	* A：给长一点时间

## 知道孤儿进程和僵尸进程吗

[孤儿进程与僵尸进程](https://www.cnblogs.com/Anker/p/3271773.html)

## 存储管理有哪些功能？

* 地址转换：把逻辑地址转化为物理地址
* 存储分配：存储空间的分配去配
* 存储保护：越界检查
* 存储共享
* 存储扩容：使用虚存的概念，程序执行的指令或数据在磁盘上，部分装入；如果没用足够的空闲内存空间，部分替换

## 存储管理有哪些模式？

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式**

## 段式和页式的区别

1. 共同点
	- 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
	- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. 区别
	- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
	- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

## 页面替换算法？

* **OPT/最佳/Belady调度算法**

	* 当要调入新页面时，首先淘汰以后不再访问的页，然后选择距现在最长时间后再访问的页

* **FIFO**

	* 总是淘汰最先调入主存的那一页，或者说主存驻留时间最长的那一页

	* 可能出现belady异常

		> 使用4个页框时的缺页次数比3个页框时的缺页多，因此这种奇怪的情况称为Belady异常

* **LRU**

	* 淘汰最近一段时间较久未被访问的那一页
	* 模拟了程序执行的局部属性，既考虑了循环性又兼顾了顺序性

* **LFU**

	* 淘汰最近一段时间内访问次数较少的页面，对OPT的模拟性比LRU更好

* **CLOCK**

	* 页面调入主存时，其引用标志位置1 
	* 访问主存页面时，其引用标志位置1 
	* 淘汰页面时，从指针当前指向的页面开始扫循环队列 
		* 把所遇到的引用标志位是1的页面的引用标志位清0，并跳过 
		* 把所遇到的引用标志位是0的页面淘汰，指针推进一步

## 反置页表是什么？为什么需要反置页表

先说说为什么需要反置页表

大多数的操作系统会为每个进程提供一个页表，如果有很多进程同时运行，那么内存中将会有很大一部分被页表占用。多级页表并不能解决这个问题，因为多级页表也是一个进程维护一张页表。反置页表可以解决这个问题。

使用反置页表的话，所有进程共同使用一张页表，这张页表中的条目的数量和内存中物理的页框的数量是一样的。

![image-20210105203555963](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105203555963.png)



## 段页式

![image-20210105204753521](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105204753521.png)

![image-20210105204800993](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210105204800993.png)

## 说说inode？

Inode存储了文件系统对象的一些元信息，如所有者、访问权限（读、写、执行）、类型（是文件还是目录）、内容修改时间、inode修改时间、上次访问时间、对应的文件系统存储块的地址，等等

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210108165201956.png" alt="image-20210108165201956" style="zoom:67%;" />

* **用户打开文件表**

	* 进程的PCB结构中保留一个files_struct，称为**用户打开文件表或文件描述符表**

	* 表项的序号为文件描述符**fd**，该登记项内登记系统打开文件表的一个入口指针**fp**
	* 通过此系统打开文件表项连接到打开文件的活动inode

* **系统打开文件表**

	* 由于一个文件可以被多个进程同时打开或一个进程同时打开多次，带来了如何管理文件当前位移量的问题
	* 是为解决多用户进程共享文件、父子进程共享文件而设置 的系统数据结构file_struct
	* 不管是同一个进程还是不同进程，每当打开一个文件时，通过此表项把用户打开文件表的表项与文件活动inode联接起来，以实现数据的访问和信息的共享
	* 多个file可以对应同一个inode，一个node可以连接0个或者多个file

* **主存活动inode表**

	* 把常用和正在使用的那些文件目录复制进主存，这样既不增加太多主存开销，又可明显减少查找时间
		* 系统为每个用户进程建立一张**活动文件表**，用户使用文件之前先通过“打开”操作，把该文件的文件目录复制到指定主存区域
		* 当不再使用该文件时，使用“关闭”操作切断和该文件目录的联系，这样，文件被打开后，可被用户多次使用，直至文件被关闭或撤销，大大减少访盘次数，提高文件系统的效率。
	* `i_count`反应共享inode的进程数目，是关闭文件时活动inode能否释放的依据
	* `i_nlink`连接计数，决定删除文件时是否将占用的存储空间释放

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210108170401525.png" alt="image-20210108170401525" style="zoom:80%;" />

## 死锁产生的条件

* 互斥条件(mutual exclusion)：系统中存在临界资源，进程应互斥地使用这些资源
* 占有和等待条件(hold and wait)：进程请求资源得不到满足而等进程请求资源得不到满足而等待时，不释放已占有的资源 
* 不剥夺条件(no preemption)：已被占用的资源只能由属主释放，不允许被其它进程剥夺
* 循环等待条件(circular wait)：存在循环等待链，其中，每个进程都在链中等待下一个进程所持有的资源，造成这组进程永远等待

## CPU寻址？

* 直接寻址，偏移地址值直接出现在执行代码中

	```assembly
	mov 寄存器，[偏移地址]
	mov [偏移地址]，寄存器
	```

* 寄存器间接寻址，偏移地址通过寄存器取得

	```assembly
	mov 寄存器，[寄存器]
	mov [寄存器]，寄存器
	```

* 寄存器相对寻址，偏移地址值通过[寄存器+偏移量值]的形式运算后获得

	```assembly
	mov 寄存器,[寄存器+偏移量值]
	mov 寄存器,ds:[寄存器+偏移量值]
	mov [寄存器+偏移量值]，寄存器
	mov ds:[寄存器+偏移量值]，寄存器
	```

	![image-20201017184431823](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20201017184431823.png)

* 基址加变址寻址，偏移地址值通过[基址寄存器+变址存储器]的形式运算后获得

	```assembly
	mov ax,[bx+si]
	add word [bx+di],0x3000
	```

* 相对基址加编址寻址

	```assembly
	mov 寄存器,[基址寄存器+变址寄存器+偏移量值]
	mov [基址寄存器+变址寄存器+偏移量值],寄存器
	```

## epoll

https://zhuanlan.zhihu.com/p/63179839

https://zhuanlan.zhihu.com/p/64138532

https://zhuanlan.zhihu.com/p/64746509

# Redis

### 缓存数据的处理流程

和cache一样

<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309162326395.png" alt="image-20210309162326395" style="zoom:67%;" />

###  为什么需要redis作缓存

从高性能和高并发来说

* **高性能**

	访问内存的速度远大于访问磁盘的速度

	假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。

	那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

* **高并发**

	一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）

> QPS（Query Per Second）：服务器每秒可以执行的查询次数；

 ### redis如何判断数据是否过期

Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。

![image-20210309163056114](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309163056114.png)

### 过期数据删除策略？

常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

### 内存淘汰机制

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中LRU
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中LRU
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### 持久化技术

[Redis(三)：持久化RDB与AOF详解#](https://www.cnblogs.com/cpaulyz/p/14480402.html#redis三：持久化rdb与aof详解)

### 事务

[Redis(四)：事务#](https://www.cnblogs.com/cpaulyz/p/14506464.html#redis四：事务)

### 缓存穿透

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

* **解决方法1：缓存无效key**

	如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

* **解决方法2：布隆过滤器**

	**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**因为多个值可能hash到同一个hashcode上

	https://www.cnblogs.com/ysocean/p/12594982.html

	本质上是bitmap，可用选择多个hash函数

### 缓存雪崩

#### 原因

* **缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。

	举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。

* **有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。** 

	举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。

#### 解决

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

**其他方案**

1. Redis缓存预热，避免冷启动
2. 通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。
3. 时间T到达后，cache中的key和value不会被清掉，而只是被标记为过期（逻辑上过期，物理上不过期），然后程序异步去刷新cache。而后续部分读线程在前面的线程刷新cache成功之前，暂时获取cache中旧的value返回。一旦cache刷新成功，后续所有线程就能直接获取cache中新的value。可以看到，这个思路很大程度上减少了排斥锁的使用（虽然并没有完全消除排斥锁）



### 缓存和数据库一致性问题

https://www.cnblogs.com/myf008/p/13367320.html?utm_source=tuicool

1. **先删缓存，再更新数据库**

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316155844132.png" alt="image-20210316155844132" style="zoom: 67%;" />

2. **先更新数据库，再删缓存**

	写操作先更新数据库，更新成功后使缓存失效

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316155932689.png" alt="image-20210316155932689" style="zoom:67%;" />

3. **先更新数据库，再更新缓存**

	写性能就比较低，可能脏写

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316160008939.png" alt="image-20210316160008939" style="zoom:67%;" />

4. **read/write through**

	CPU向cache写入数据时，同时向memory(后端存储)也写一份，使cache和memory的数据保持一致。

5. **写回。在更新数据的时候**

	cpu更新cache时，只是把更新的cache区标记一下，并不同步更新memory(后端存储)。只是在cache区要被新进入的数据取代时，才更新memory(后端存储)

# 并发

https://nyimac.gitee.io/2020/06/08/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/

## 什么是线程和进程？

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

参考OS扯

**线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；**

## 从JAVA角度谈谈进程和线程的关系

在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

比如在JVM中，堆和方法区是进程共享的，PC、本地方法栈、虚拟机栈是线程私有的

> 补充：混合型、内核型、用户型进程
>
> 值得一提的是，我认为JAVA里的进程属于混合型进程。
>
> 1、证明java线程不是纯粹用户级线程：在java中起一堆线程，系统可以感知到。从java应用程序中的某个线程阻塞，是不会引起整个进程的阻塞，从这两点看，java线程绝不是纯粹的用户级线程。 （线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程）
>
> 2、再来，证明java线程不是纯粹内核级线程：这点比较直观，如果使用纯粹的内核级线程，那么有关线程的所有管理工作都是内核完成的，用户程序中没有管理线程的代码。显然，java线程库提供了大量的线程管理机制，因此java线程绝不是纯粹的内核级线程。 综上，java线程是混合型的线程模型，一般而言是通过lwp将用户级线程映射到内核线程中。
>
> https://blog.csdn.net/jinlong59421/article/details/105816973/
>
> https://blog.csdn.net/gdhgr/article/details/81945993

## 线程的六个状态

![image-20210309174527981](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309174527981.png)

![image-20210309174536575](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309174536575.png)

> 订正：原图中 wait到 runnable状态的转换中，`join`实际上是`Thread`类的方法，但这里写成了`Object`。

> 操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。

## 如何避免死锁

1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
2. **破坏请求与保持条件** ：一次性申请所有的资源。
3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

死锁避免：银行家算法（把锁看作资源）

## sleep和wait方法的异同

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- `wait()` 通常被用于线程间交互/通信，`sleep() `通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

## 什么用start方法而不用run

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

## wait()、notify()和notifyAll()方法为什么属于Object

* 原因一：Java中，任何对象都可以作为锁，既然wait是放弃对象锁，当然就要把wait定义在这个对象所属的类中。更通用一些，由于所有类都继承于Object，我们完全可以把wait方法定义在Object类中，这样，当我们定义一个新类，并需要以它的一个对象作为锁时，不需要我们再重新定义wait方法的实现，而是直接调用父类的wait(也就是Object的wait)，此处，用到了Java的继承。
* 原因二：有的人会说，既然是线程放弃对象锁，那也可以把wait定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。

综上所述，wait()、notify()和notifyAll()方法要定义在Object类中。

## synchronized底层原理

* **同步语句块**

	`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

	当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 对象监视器 `monitor` 的持有权。

	* 在执行`monitorenter`时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。

	* 在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

	```java
	public class SynchronizedDemo {
	    public void method() {
	        synchronized (this) {
	            System.out.println("synchronized 代码块");
	        }
	    }
	}
	```

	![image-20210309185734152](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309185734152.png)

* **同步方法**

	```java
	public class SynchronizedDemo2 {
	    public synchronized void method() {
	        System.out.println("synchronized 方法");
	    }
	}
	```

	`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

	![image-20210309185830392](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309185830392.png)

## monitor原理？

![image-20210315222705627](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210315222705627.png)

- 当线程执行到临界区代码时，如果使用了synchronized，会先查询synchronized中所指定的对象(obj)**是否绑定了Monitor**。

	- 如果**没有绑定**，则会先去去与Monitor绑定，并且将Owner设为当前线程。
	- 如果已经绑定，则会去查询该Monitor是否已经有了Owner
		- 如果没有，则Owner与将当前线程绑定
		- 如果有，则放入EntryList，进入阻塞状态(blocked)

- 当Monitor的Owner将临界区中代码执行完毕后，Owner便会被清空，此时EntryList中处于**阻塞**状态的线程会被**叫醒并竞争**，此时的竞争是**非公平的**

- **注意**：

	- 对象在使用了synchronized后与Monitor绑定时，会将对象头中的**Mark Word**置为Monitor指针。
	- 每个对象都会绑定一个**唯一的Monitor**，如果synchronized中所指定的对象(obj)**不同**，则会绑定**不同**的Monitor

- 锁对象调用wait方法（obj.wait），就会使当前线程进入WaitSet中，变为WAITING状态。

- 处于BLOCKED和WAITING状态的线程都为

	阻塞

	状态，CPU都不会分给他们时间片。但是有所区别：

	- BLOCKED状态的线程是在竞争对象时，发现Monitor的Owner已经是别的线程了，此时就会进入EntryList中，并处于BLOCKED状态
	- WAITING状态的线程是获得了对象的锁，但是自身因为某些原因需要进入阻塞状态时，锁对象调用了wait方法而进入了WaitSet中，处于WAITING状态

- BLOCKED状态的线程会在锁被释放的时候被唤醒，但是处于WAITING状态的线程只有被锁对象调用了notify方法(obj.notify/obj.notifyAll)，才会被唤醒。

## 锁优化

的状态从低到高依次为**无锁->偏向锁->轻量级锁->重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。

**自适应锁**：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。

**锁消除**：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。

**锁粗化**：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。

**偏向锁**：当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时都不需要CAS来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置-XX:+UseBiasedLocking开启偏向锁。

**轻量级锁**：JVM的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM将会使用CAS方式来尝试获取锁，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。

整个锁升级的过程非常复杂，我尽力去除一些无用的环节，简单来描述整个升级的机制。

![](https://pic4.zhimg.com/v2-a04036ccc8906893955e06a47e97d38b_r.jpg)

## （重要）谈谈synchronized锁升级的过程？

* 锁有四种状态，分别是**无锁、偏向锁、轻量锁、重量锁**。

* 为什么要有这四种状态

	* 第一因为避免线程状态转化造成的。OS中学到的多线程在临界区的方法一般是这里的重量级锁，即挂起等待，但是这种状态的转换需要用户、内核态的转变，十分耗费时间，其实有时候只需要等一下（自旋）就可以了，所以引入了偏向锁、轻量锁，还引入了自旋

* 需要掌握的是对象头

	![image-20210310213926968](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210310213926968.png)

	区别不同锁的重要标志是最后两位

* 无锁就不谈了

* 偏向锁

	初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，**线程并不会主动释放偏向锁**。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。

	释放锁偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。

	假设这时候锁是偏向锁，A在用，这时候B来了，先CAS，发现偏向锁的线程ID不是自己，就告诉JVM，等待一个全局安全点，这时候会检查A是否还是锁定状态，如果是就升级为偏向锁，如果不是就降级为无锁，然后B去竞争偏向锁

	A接受到消息之后，暂停当前的任务(实际上就是虚拟机暂停了A)，先将偏向锁取消，也就是CAS操作，把类头的那个字段清空。并且把类头上面，的锁的标志位，改为，我们接下来要说的`轻量级锁`。

* 轻量锁

	A和B线程都把对象的类头重的相关字段复制到自己的线程栈中。

	A线程通过CAS操作，把共享对象的类头重的相关字段的内容修改为自己新建的记录空间的地址。
	这个时候B就会尝试去获取轻量级锁

	然后B获取不到，会进入自旋状态也就是会进行多次CAS操作尝试。下面就会有两种情况。

	如果A线程通过，CAS操作，释放了锁，B线程随后获取到了，那么就会正常执行下去。

	如果B线程尝试了多次之后，还没得到，虚拟机就暂停A，然后会把锁的标志位改成重量级锁，并

	把线程B的状态信息写入到Monitor的阻塞队列中，线程B进入到阻塞状态，以及A的信息也写入monitor，然后恢复A的执行。

* 重量锁

	一看最后两位，是重量锁，那不等了，直接monitor的等待队列挂起

**从上面的情况可以看到，升级的过程，总是要暂停那个正在执行的线程，然后进行锁升级，升级完成后，恢复执行。那么如果锁等级可逆。那么可能会存在锁升级过多次出现的情况，（可能对大部分情况来说）对性能消耗大。所以JVM实现的这个锁升级是不可逆的。也就是，例如不可以从重量级锁，回到之前的锁。**

> 参考
>
> [Java6及以上版本对synchronized的优化](https://www.cnblogs.com/wuqinglong/p/9945618.html)
>
> [深度分析：锁升级过程和锁状态，看完这篇你就懂了！](https://www.cnblogs.com/lwh1019/p/13093581.html)
>
> https://www.zhihu.com/question/384014892/answer/1117940282
>
> [理解JVM对synchronized进行的优化](https://blog.csdn.net/u011580175/article/details/101495253/)
>
> [synchronized的实现原理及锁优化](https://www.cnblogs.com/xdyixia/p/9364247.html)

## synchronized和ReentrantLock

* **synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

	`synchronized` 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 `synchronized` 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。`ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

* **可中断**

	如果某个线程处于阻塞状态，可以调用其interrupt方法让其停止阻塞，获得锁失败

* **可以设置超时时间**

	tryLock

* **可以设置为公平锁 (先到先得)**

* **支持多个条件变量( 具有多个waitset)**

	ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持**多个**条件变量的，这就好比

	- synchronized 是那些不满足条件的线程都在一间休息室等消息
	- 而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤 醒
	- await 前需要**获得锁**
	- await 执行后，会释放锁，进入 conditionObject 等待
	- await 的线程被唤醒（或打断、或超时）取重新竞争 lock 锁
	- 竞争 lock 锁成功后，从 await 后继续执

## ThreadLocal原理

在每个线程内部都有一个名为threadLocals的成员变量，该变量的类型为HashMap，其中**key为我们定义的ThreadLocal变量的this引用，value则为我们使用set方法设置的值**。每个线程的本地变量存放在线程自己的内存变量threadLocals中

只有当前线程**第一次调用ThreadLocal的set或者get方法时才会创建threadLocals**（inheritableThreadLocals也是一样）。其实每个线程的本地变量不是存放在ThreadLocal实例里面，而是存放在调用线程的threadLocals变量里面

## ThreadLocal为什么会内存泄漏

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

```java
      static class Entry extends WeakReference<ThreadLocal<?>> {
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }Copy to clipboardErrorCopied
```

## 线程池创建方式

1. **构造函数**

	![image-20210310000710735](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210310000710735.png)

2. **通过 Executor 框架的工具类 Executors 来实现**

	- **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
		- 都用到LinkedBlockingQueue
	- **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量（maximumPoolSize）为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。
		- cached：SynchronousQueue，长度是0
		- scheduled：DelayedWorkQueue，长度无上限

https://zhuanlan.zhihu.com/p/112527671

## 线程池参数

**`ThreadPoolExecutor` 3 个最重要的参数：**

- `corePoolSize` : 核心线程数线程数定义了最小可以同时运行的线程数量。
- `maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- `workQueue`: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. `keepAliveTime`:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. `unit` : `keepAliveTime` 参数的时间单位。
3. `threadFactory` :executor 创建新线程的时候会用到。
4. `handler` :饱和策略。关于饱和策略下面单独介绍一下。

## 什么是饱和策略？

**`ThreadPoolExecutor` 饱和策略定义:**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，`ThreadPoolTaskExecutor` 定义一些策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

## 线程池大小变化

![image-20210309234004528](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309234004528.png)

**新提交一个任务时的处理流程很明显：**

1. 如果当前线程池的线程数还没有达到基本大小(poolSize < corePoolSize)，**无论是否有空闲的线程新增一个线程处理新提交的任务；**

2. 如果当前线程池的线程数大于或等于基本大小(poolSize >= corePoolSize) **且任务队列未满时**，就将新提交的任务提交到阻塞队列排队，等候处理workQueue.offer(command)；

3. 如果当前线程池的线程数大于或等于基本大小(poolSize >= corePoolSize) **且任务队列满时**；

	* 当前poolSize<maximumPoolSize，那么就**新增线程**来处理任务；

	* 当前poolSize=maximumPoolSize，那么意味着线程池的处理能力已经达到了极限，此时要拒绝新增加的任务。至于如何拒绝处理新增的任务，取决于线程池的饱和策RejectedExecutionHandler。

## 线程池示例

```java
    private static final int CORE_POOL_SIZE =5 ;
    private static final int MAX_POOL_SIZE = 10;
    private static final int QUEUE_CAPACITY = 30;
    private static final Long KEEP_ALIVE_TIME = 1L;
    public static void main(String[] args) {

        //使用阿里巴巴推荐的创建线程池的方式
        //通过ThreadPoolExecutor构造函数自定义参数创建
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                CORE_POOL_SIZE,
                MAX_POOL_SIZE,
                KEEP_ALIVE_TIME,
                TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(QUEUE_CAPACITY),
                new ThreadPoolExecutor.CallerRunsPolicy());
//        ExecutorService executor = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 15; i++) {
            executor.execute(new MyRunnable(""+i));
        }
        executor.shutdown();
    }
```

![image-20210309233751449](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309233751449.png)

修改

```java
    private static final int CORE_POOL_SIZE =5 ;
    private static final int MAX_POOL_SIZE = 10;
    private static final int QUEUE_CAPACITY = 5;
    private static final Long KEEP_ALIVE_TIME = 1L;
    public static void main(String[] args) {

        //使用阿里巴巴推荐的创建线程池的方式
        //通过ThreadPoolExecutor构造函数自定义参数创建
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                CORE_POOL_SIZE,
                MAX_POOL_SIZE,
                KEEP_ALIVE_TIME,
                TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(QUEUE_CAPACITY),
                new ThreadPoolExecutor.CallerRunsPolicy());
//        ExecutorService executor = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 11; i++) {
            executor.execute(new MyRunnable(""+i));
        }
        executor.shutdown();
    }
```



![image-20210309233911524](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309233911524.png)

分析：第11个任务过来，核心线程已满，队列已满，所以会创建新线程

## JMM

JMM 即 Java Memory Model，它定义了**主存（共享内存）、工作内存（线程私有）**抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。

**JMM体现在以下几个方面**

- 原子性 - 保证指令不会受到线程上下文切换的影响
- 可见性 - 保证指令不会受 cpu 缓存的影响
	- volatile，直接写入主存
- 有序性 - 保证指令不会受 cpu 指令并行优化的影响
	- 防止指令重排

## 进程通信

(1)  管道(PIPE) 
 (2)  命名管道(FIFO) 
 (3)  信号量(Semphore) 
 (4)  消息队列(MessageQueue) 
 (5)  共享内存(SharedMemory) 
 (6)  Socket



## happens-before

  　　1. 单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。

　　首先是单线程的 HB ，前面的操作产生的结果必须对后面的操作可见。而不是前面的操作必须先于后面的操作执行，比如按照  as-if-serial 语义，没有数据依赖的两条指令是可以进行重排序的。而这种情况对于 HB  原则来说，因为两条指令都没有产生对方需要的结果，而不需要对对方可见，及时执行顺序被调转也是符合 HB 原则的。

  　　2. 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。

　　个人理解强调的是解锁操作在多线程环境的可见性。一个线程进行了解锁操作，对于晚于该操作的加锁操作必须能够及时感应到锁的状态变化。解锁操作的结果对后面的加锁操作一定是可见的，无论两个是否在一个线程。

  　　3. volatile的happen-before原则： 对一个volatile变量的写操作happen-before对此变量的任意操作。

　　对 volatile 变量的写操作的结果对于发生于其后的任何操作的结果都是可见的。x86 架构下volatile 通过内存屏障和缓存一致性协议实现了变量在多核心之间的一致性。

  　　4. happen-before的传递性原则：  如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。

　　HB 可以说是两项操作之间的**偏序关系**，满足偏序关系的各项性质，我们都知道偏序关系中有一条很重要的性质：传递性，所以Happens-Before也满足传递性。这个性质非常重要，通过这个性质可以推导出两个没有直接联系的操作之间存在Happens-Before关系

  　　5. 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。

　　start 放法与其它方法可能并没有数据依赖关系，但是显而易见的，为了程序的正确性，我们必须做到这一点。start 方法造成的函数副作用必须对其它方法可见。

## AQS

[从ReentrantLock的实现看AQS的原理及应用](https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html)

[Java 并发高频面试题：聊聊你对 AQS 的理解？](https://zhuanlan.zhihu.com/p/86072774)

**AbstractQueuedSynchronizer，抽象队列同步器**

![image-20210317125758674](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210317125758674.png)

# 数据库总结

## 数据库原理部分

### ACID

1. 原子性（Atomicity）

	事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

	回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

2. 一致性（Consistency）

	数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。

3. 隔离性（Isolation）

	一个事务所做的修改在最终提交以前，对其它事务是不可见的。

4. 持久性（Durability）

	一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

	系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。
- 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对系统崩溃的情况

![image-20210222211441868](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222211441868.png)

### 并发一致性问题及隔离级别

1. **丢失修改**

	T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222211628500.png" alt="image-20210222211628500" style="zoom: 67%;" />

	**解决办法**：未提交读（Read Uncommitted）：读事务不加锁，修改数据时加了排它锁。这种隔离级别，会导致脏读、不可重复读以及幻读。

	即：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁

2. **脏读**

  T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据

  <img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222211704053.png" alt="image-20210222211704053" style="zoom:67%;" />

  **解决办法**：已提交读（Read Committed）：在未提交读的基础上，在事务 B 读取数据时增加了共享锁，==一旦读取，立即释放锁==，事务 A 读取修改数据时增加了行级排他锁，直到事务结束才释放锁。 也就是说，事务 B 在读取数据时，事务 A 只能读取数据，不能修改。当事务 B 读取到数据后，事务 A 才能修改。 这种隔离级别，可以避免脏读，但依然存在不可重复读以及幻读的问题。

3. **不可重复读**

  T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同

  <img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222211740252.png" alt="image-20210222211740252" style="zoom:67%;" />

  **解决办法**：可重复读（Repeatable Read）：在已提交读的基础上，在事务 B 读取数据时增加了共享锁，==事务结束，才释放锁==，事务 A 读取修改数据时增加了行级排他锁，直到事务结束才释放锁。 也就是说，事务 B 在没有结束事务时，事务 A 只能读取数据，不能修改。当事务 B 结束事务，事务 A 才能修改。 这种隔离级别，可以避免脏读、不可重复读，但依然存在幻读的问题。

4. **幻读**

	T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同

	> 为什么会出现幻读？锁没加上，假设id有3,4,5，锁定id>3的数据，是指的4，5及**后面的数字都会被锁定，**因为此时如果不锁定没有的数据，例如当加入了新的数据id=6，就会出现幻读

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222211817078.png" alt="image-20210222211817078" style="zoom:67%;" />

	**解决办法**：可序列化（Serializable）：在事务 A 读取数据时增加了共享锁，事务结束，才释放锁，事务 B 读取修改数据时增加了表级排他锁，直到事务结束才释放锁。

### 谈谈乐观锁和悲观锁

* 悲观锁

	悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

* 乐观锁

	乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。
	乐观锁策略:提交版本必须大于记录当前版本才能执行更新

### 范式

**1．第一范式(确保每列保持原子性)**

第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。

**2．第二范式(确保表中的每列都和主键相关)**

要求每一个非主属性既不部分依赖于码也不传递依赖于码

第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

**3．第三范式(确保每列都和主键列直接相关,而不是间接相关)**

消除间接依赖

第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。

比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。如下面这两个表所示的设计就是一个满足第三范式的数据库表。

**4. BCNF**

消除了主属性对候选码的部分和传递函数依赖。

在学生信息表里，学号是一个候选码，学号可确定学生姓名；(班级,学生姓名）也是一组候选码，有(班级,学生姓名）->学号，因此在主属性间形成了传递依赖。

## 语句

### dual表

https://blog.csdn.net/xushiyu1996818/article/details/81203596?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control

## 外键约束

RESTRICT（约束）：如果出现在删除时，意思是约束外键主键did记录（主表中的记录）不能直接删除，必须先删除被约束的表（从表）字段中dept_id所有这个外键主键值对应的记录，才能删除外键约束（主表中的记录）

NO ACTION：

CASCADE：删除选择这个时，删除主表中的记录时，主表中的这个主键id关联的从表的这个id值所在的记录也会被删除。建议不选。

SET NULL ：删除选择这个时，如果从表（被约束的字段所在的表中）被约束的字段的值设置为可以为空时，那么当删除主表的记录时，主表中被删除的这个记录对应的主键值（约束从表字段的那个值）在从表中对应的字段中出现的那个记录的被约束字段的值就会变为NULL。

## MySQL部分

### varchar可以存多少个汉字和数字？

具体还是要看版本的：

4.0版本以下，varchar(100)，指的是100字节，如果存放UTF8汉字时，只能存33个（每个汉字3字节）

* GBK：一个汉字=2个字节
* UTF-8：一个汉字=3个字节

5.0版本以上，varchar(100)，指的是100字符，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放100个。

### 架构

![image-20210222201522649](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222201522649.png)

最上层用于连接、线程处理的部分并不是 MySQL 『发明』的，很多服务都有类似的组成部分；

第二层中包含了大多数 MySQL 的核心服务，包括了对 SQL 的解析、分析、优化和缓存等功能，存储过程、触发器和视图都是在这里实现的；

而第三层就是 MySQL 中真正负责数据的存储和提取的存储引擎，例如：[InnoDB](https://en.wikipedia.org/wiki/InnoDB)、[MyISAM](https://en.wikipedia.org/wiki/MyISAM) 等，文中对存储引擎的介绍都是对 InnoDB 实现的分析

### InnoDB中的数据存储

在 InnoDB 存储引擎中，所有的数据都被**逻辑地**存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page）

![image-20210222201625736](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222201625736.png)

### 如何存储表

MySQL 使用 InnoDB 存储表时，会将**表的定义**和**数据索引**等信息分开存储，其中前者存储在 `.frm` 文件中，后者存储在 `.ibd` 文件中

![image-20210222201805469](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222201805469.png)

无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 `.frm` 文件用来描述表的格式或者说定义；`.frm` 文件的格式在不同的平台上都是相同的

### 数据页结构

页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 B-Tree 节点就是实际存放表中数据的页面，我们在这里将要介绍页是如何组织和存储记录的；首先，一个 InnoDB 页有以下七个部分

![image-20210222202237287](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222202237287.png)

每一个页中包含了两对 header/trailer：内部的 Page Header/Page Directory 关心的是页的状态信息，而 Fil Header/Fil Trailer 关心的是记录页的头信息。

在页的头部和尾部之间就是用户记录和空闲空间了，每一个数据页中都包含 Infimum 和 Supremum 这两个**虚拟**的记录（可以理解为占位符），Infimum 记录是比该页中任何主键值都要小的值，Supremum 是该页中的最大值

User Records 就是整个页面中真正用于存放行记录的部分，而 Free Space 就是空余空间了，它是一个链表的数据结构，为了保证插入和删除的效率，整个页面并不会按照主键顺序对所有记录进行排序，它会自动从左侧向右寻找空白节点进行插入，行记录在物理存储上并不是按照顺序的，它们之间的顺序是由 `next_record` 这一指针控制的。

B+ 树在查找对应的记录时，并不会直接从树中找出对应的行记录，它只能获取记录所在的页，将整个页加载到内存中，再通过 Page Directory 中存储的稀疏索引和 `n_owned`、`next_record` 属性取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。

### 索引

InnoDB 中对于数据是如何存储的；InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行

B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度

![image-20210222202454389](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222202454389.png)

### 为什么使用B+树？

> [为什么 MySQL 使用 B+ 树](https://draveness.me/whys-the-design-mysql-b-plus-tree/)

* 哈希

	哈希作为底层的数据结构的表能够以 `O(1)` 的速度处理单个数据行的增删改查，但是面对范围查询或者排序时就会导致全表扫描的结果，而 B 树和 B+ 树虽然在单数据行的增删查改上需要 `O(log n)` 的时间，但是它会将索引列相近的数据按顺序存储，所以能够避免全表扫描

* B树

	计算机在读写文件时会以页为单位将数据加载到内存中。页的大小可能会根据操作系统的不同而发生变化，不过在大多数的操作系统中，页的大小都是 `4KB`，你可以通过如下的命令获取操作系统上的页大小

	B 树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机 I/O，而 B+ 树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机 I/O

* B+树

	由于所有的节点都可能包含目标数据，我们总是要从根节点向下遍历子树查找满足条件的数据行，这个特点带来了大量的随机 I/O，也是 B 树最大的性能问题。

	B+ 树中就不存在这个问题了，因为所有的数据行都存储在叶节点中，而这些叶节点可以**通过『指针』依次按顺序连接**，当我们在如下所示的 B+ 树遍历数据时可以直接在多个子节点之间进行跳转，这样能够节省大量的磁盘 I/O 时间，也不需要在不同层级的节点之间对数据进行拼接和排序；通过一个 B+ 树最左侧的叶子节点，我们可以像链表一样遍历整个树中的全部数据，我们也可以引入双向链表保证倒序遍历时的性能

### 什么是窄索引和宽索引？回读？

对于查询 `SELECT id, username, age FROM users WHERE username="draven"` 来说，(id, username) 就是一个窄索引，因为该索引没有包含存在于 SQL 查询中的 age 列，而 (id, username, age) 就是该查询的一个宽索引了，它**包含这个查询中所需要的全部数据列**。

宽索引能够避免二次的随机 IO，而窄索引就需要在对索引进行顺序读取之后再根据主键 id 从主键索引中查找对应的数据：

![image-20210223145924043](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210223145924043.png)

对于窄索引，每一个在索引中匹配到的记录行最终都需要执行另外的随机读取从聚集索引中获得剩余的数据，如果结果集非常大，那么就会导致随机读取的次数过多进而影响性能

![image-20210223145932118](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210223145932118.png)

### 聚簇索引和非聚簇索引（主索引和辅助索引）

数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index），它们之间的最大区别就是，聚集索引中存放着一条行记录的全部信息，而辅助索引中只包含索引列和一个用于查找对应行记录的『书签』

* 聚集索引

	聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该**有且仅有一个**聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照**聚集索引**的顺序存放的。

	当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作

	![image-20210222202956255](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222202956255.png)

* 辅助索引

	辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个书签就是当前记录的主键

	如果在表 `users` 中存在一个辅助索引 `(first_name, age)`，那么它构成的 B+ 树大致就是上图这样，按照 `(first_name, age)` 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录

	![image-20210222203055234](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222203055234.png)



在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，**只是主索引要求key是唯一的，而辅助索引的key可以重复**

![image-20210222203241676](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210222203241676.png)

> **（1）innodb和myisam的主键索引是聚集索引还是非聚集索引？**
>
> 在Innodb下主键索引是聚集索引，在Myisam下主键索引是非聚集索引
>
> 
>
> **（2）聚簇索引和非聚簇索引的区别？**
>
> 聚簇索引的叶子节点存放的是主键值和数据行，**支持覆盖索引**；二级索引的叶子节点存放的是主键值或指向数据行的指针。
>
> 由于节子节点(数据页)只能按照一颗B+树排序，故**一张表只能有一个聚簇索引**。辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引

### MVCC

MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。

* **已提交读和可重复读的区别？**

	已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView（[面试官：谈谈你对Mysql的MVCC的理解？](https://baijiahao.baidu.com/s?id=1629409989970483292&wfr=spider&for=pc)）

MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的

* DB_TRX_ID
	6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID

* DB_ROLL_PTR
	7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）

* DB_ROW_ID
	6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引

![image-20210315172931946](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210315172931946.png)



1. 如果trx_id<low_limit_id，那么说明就是之前事务的数据，直接返回，也就对应了小明第一次开启事务查询的场景
2. 如果trx_id>low_limit，trx_id还在[low_limit_id,up_limit_id]范围之内，并且trx_id在m_ids中，就会根据roll_pointer去查找undo log日志链，找到之前版本的数据，对应的就是小红修改后小明再次查询的场景
3. 如果trx_id=creator_trx_id，那么说明就是自己修改的，直接返回就好了，对应的就是小明自己去修改数据的场景

### MySQL如何解决幻读？

> [MySQL 是如何解决幻读的](https://www.cnblogs.com/wudanyang/p/10655180.html)

MVCC解决了基于快照读下的幻读，事务 读 取的 行， 要么 是在 事务 开始 前 已经 存在 的， 要么 是 事务 自身 插入 或者 修 改过 的。

但是MVCC无法解决当前读下的幻读

* 快照读

	在MVCC下，如果是RR级别，在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView，显然不会出现幻读

* 当前读

	**next-key 锁**

	著作权归https://www.pdai.tech所有。 链接：https://www.pdai.tech/md/db/sql/sql-db-theory.html

	* （记录锁）Record Locks

		锁定一个记录上的索引，而不是记录本身。

		如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

	* 间隙锁Gap Locks

		锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。

		```sql
		SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
		```

	* Next-Key Locks

		它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值: 10, 11, 13, and 20，那么就需要锁定以下区间:

		```sql
		(negative infinity, 10]
		(10, 11]
		(11, 13]
		(13, 20]
		(20, positive infinity)
		```

### 日志

#### UNDO LOG

回滚日志

* 保证事务的**原子性**，就需要在异常发生时，对已经执行的操作进行**回滚**

* 在 MySQL 中，恢复机制是通过*回滚日志*（undo log）实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入

#### REDO LOG

重做日志

* 事务的**持久性**也是通过日志来实现的
* MySQL 使用重做日志（redo log）实现事务的持久性，重做日志由两部分组成，一是内存中的重做日志缓冲区，因为重做日志缓冲区在内存中，所以它是易失的，另一个就是在磁盘上的重做日志文件，它是持久的
* 我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL 会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上，图中的第 4、5 步就是在事务提交时执行的
* InnoDB 中，重做日志都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据

![image-20210223150648203](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210223150648203.png)

> 1. 发生错误或者需要回滚的事务能够成功回滚（原子性）；
> 2. 在事务提交后，数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）；

#### 事务日志

在数据库中，这两种日志经常都是一起工作的，我们**可以**将它们整体看做一条事务日志，其中包含了事务的 ID、修改的行元素以及修改前后的值

![image-20210223150824453](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210223150824453.png)

### 说说数据库的行锁和表锁？

行锁：操作时只锁某一（些）行，不对其它行有影响。开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高。

表锁：即使操作一条记录也会锁住整个表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突概率高，并发度最低。

页锁：操作时锁住一页数据（16kb）。开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般。

InnoDB 有行锁和表锁，MyIsam 只有表锁。

 ### InnoDB 的行锁是怎么实现的？

InnoDB 行锁是通过索引上的索引项来实现的。意味者：只有通过索引条件检索数据，InnoDB 才会使用行级锁，否则，InnoDB将使用表锁！

* 对于主键索引：直接锁住锁住主键索引即可。

* 对于普通索引：先锁住普通索引，接着锁住主键索引，这是因为一张表的索引可能存在多个，通过主键索引才能确保锁是唯一的，不然如果同时有2个事务对同1条数据的不同索引分别加锁，那就可能存在2个事务同时操作一条数据了。

### 一条MySQL语句的执行过程？

[MySQL - 一条 SQL 的执行过程详解](https://www.pdai.tech/md/db/sql-mysql/sql-mysql-execute.html)

# 网络

![](https://images.xiaozhuanlan.com/photo/2019/497a4707a94614e44401023c95015316.jpg)

## 应用层

> 报文 message

### OSI

会话、表示、应用层

会话层

* 作用：建立、管理、终止应用程序之间的会话
	* 例如是半双工还是其他的（传输层确定能通信，会话层确定怎么通信）
* checkpoint 检查点
	* 把会话分割成明显的会话单元session，过去的成为对话dialogue
	* 会话分离是有序地初始化、终止和管理通讯
	* 这样当网络出现故障就从最后一个检查点开始重传数据（下载100M的文件，下载到95M网络断线只需要再次下载最后5M）

展示层

* 负责以接收设备可理解的方式呈现数据

* 格式化数据
	* ASCII和EBCDIC
	* GIF和JPEG
* 压缩数据
* 数据加密

### 应用层协议?

* HTTP	

	* 超文本传输协议
	* URL := `<URL的访问方式>://<主机>:<端口>/<路径>`

		* 无状态的
		* 无连接的，虽然使用了面向连接的TCP

* FTP

	* 使用TCP，可靠、面向连接的服务
	* 首先建立**控制**连接 **21端口**
	* 然后建立**数据**传输需要的连接 **20端口**

* TFTP

	* UDP
	* 小且容易实施

* Telnet

	* 远程登录

* SMTP POP IMAP

	* TCP

	* ![image-20210226195429347](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226195429347.png)

	* ![image-20210226195438347](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226195438347.png)

	* >   **IMAP和POP有什么区别？** 
		>
		>   POP允许电子邮件客户端下载服务器上的邮件，但是您在电子邮件客户端的操作（如：移动邮件、标记已读等），这是不会反馈到服务器上的，比如：您通过电子邮件客户端收取了QQ邮箱中的3封邮件并移动到了其他文件夹，这些移动动作是不会反馈到服务器上的，也就是说，QQ邮箱服务器上的这些邮件是没有同时被移动的  。但是IMAP就不同了，电子邮件客户端的操作都会反馈到服务器上，您对邮件进行的操作（如：移动邮件、标记已读等），服务器上的邮件也会做相应的动作。也就是说，IMAP是“双向”的。 
		>
		>   同时，IMAP可以只下载邮件的主题，只有当您真正需要的时候，才会下载邮件的所有内容。 

* MIME

	* 将非ASCII码转为ASCII码

* DNS

	* 域名解析，域名翻译成IP

	* www.sina.com 从左到右 为第3、第2、顶层域名

	* 两种形式：递归、迭代

		![image-20210226194354924](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226194354924.png)

### 在浏览器中输入url地址 ->> 显示主页的过程

详细参考https://segmentfault.com/a/1190000006879700

1. DNS解析
	* 优化：浏览器缓存，系统缓存（host文件），路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存
2. TCP连接
3. HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
	* 插叙：前端优化，如CSS精灵、CDN、懒加载等
6. 连接结束

### 谈谈TCP中的长连接和短链接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接

### 为什么说http协议是无状态的

HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和上一次打开这个服务器上的网页之间没有任何联系。

HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）

### 既然http协议是无状态的，那么如何保存用户状态？

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP   协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session  的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP  协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session  存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID  来方式来跟踪。

> cookie被禁用？
>
> 最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

### Cookie的作用是什么？和Session有什么区别？

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

**Cookie 一般用来保存用户信息** 比如①我们在 Cookie  中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token  重写)；③登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

### HTTP1.0 HTTP1.1 HTTP2.0

* HTTP1.1 
	* **长连接** : **在HTTP/1.0中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1起，默认使用长连接** ,默认开启Connection： keep-alive。
	* **HTTP/1.1的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。

* HTTP2.0
	* **多路复用**（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
	* **header压缩**，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
	* **服务端推送**（server push），同SPDY一样，HTTP2.0也具有server push功能。

### URI URL

- URI(Uniform Resource Identifier) 是同一资源标志符，可以唯一标识一个资源。
- URL(Uniform Resource Location) 是同一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

### HTTP和HTTPS

SSL：（Secure Socket  Layer，安全套接字层），位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以实现客户端和服务器之间的安全通讯。该协议由两层组成：SSL记录协议和SSL握手协议。

TLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。

https://segmentfault.com/a/1190000018992153

### HTTPS是什么?

https://zhuanlan.zhihu.com/p/43789231



## 传输层

> segment

* 将应用层数据分段
* 建立端到端的操作
* 将segment从主机发送到主机
* 流量控制和可靠性

### 谈谈路由器转发的过程？

1. 提取IP数据报告首部中的目的IP地址
2. 判断目的IP地址所在的网络是否与本路由器直接相连。如果是，就直接交付给目的网洛：如果不是执行3）
3. 检查路由器表中是否有目的IP地址的特定主机路由。如果有，按特定主机路由转发：如果没有，执行4）
4. 逐条检查路由表。若找到匹配路由，则按照路由表进行转发：若所有路由均不匹配，则执行5
5. 若路由表中设置有默认路由，则按照默认路由表转发：否则，执行6）
6. 向源主机报错。

MAC地址的变化如下：

A-----(B1-B2)-----(C1-C2)-------E


假设拓扑图是这个样子吧，B1和B2是路由器B上的两个接口，C1和C2是路由器C上的两个接口，A和E是PC，由主机A向主机E发送数据包，那么在主机A形成的数据包的目的IP就是E的IP，源IP就是主机A的IP地址，目标MAC地址就是B1的MAC地址，源MAC地址就是A的MAC地址

由A发给路由器B，B经过重封装后，源IP和目标IP是不变的，源MAC地址变成B2的MAC地址，目标MAC地址变成C1的MAC地址，封装完成发送给路由器C，路由器C接收到数据包后和B做的操作是一样的，源IP和目标IP的不变的，源MAC地址变成C2的MAC地址，目标MAC地址变成主机E的MAC地址，然后发送给主机E，这样E就收到了这个数据包，当恢复数据包的时候就是把收到的数据包的源IP地址（主机A的IP地址）和源MAC地址（接口C2的MAC地址）作为他的目标IP和目标MAC地址

### TCP报文

![image-20210226220857876](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226220857876.png)

###  三次握手及相关问题

![image-20200818200236673](https://img2020.cnblogs.com/blog/1958143/202008/1958143-20200820094900154-1369704410.png)

* 第一次握手：客户端发送一个SYN=1，ACK=0的TCP段
* 第二次握手：服务端发送一个SYN=1，ACK=1的TCP段
	* 如果没有监听端口，返回一个RST=1的TCP段
* 第三次握手：客户端发送一个SYN=0，ACK=1的TCP段

> Q1：为什么要三次握手？
>
> 主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。
>
> 如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。
>
> Q2：为什么要传回SYN？
>
> 接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了
>
> Q3：传了 SYN,为啥还要传 ACK
>
> 双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证

### 四次挥手及相关问题

![image-20210316192053481](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210316192053481.png)

* 客户端发送一个FIN=1的报文
	* 进入进入FIN-WAIT-l (终止等待1)状态，等待服务器的确认。
* 服务器发送FIN=0，ACK=1的确认报文
	* 进入CLOSEWAIT(关闭等待)状态，TCP 服务器进程这时应通知高层应用进程
	* (half-close)状态，即A 己经没有数据要发送了，但B 若发送数据， A 仍要接收。
	* A 收到来自B 的确认后，就进入FIN-WAIT-2 (终止等待2) 状态
* 若服务器没有要发送的报文了，就向客户端发送FIN=1的释放报文
	* **确认号仍要和前述的一致**
	* B 就进入LAST-ACK (最后确认)状态
* 客户端收到连接释放报文后，发送FIN=0,ACK=1的确认报文
	* 客户端进入TIME-WAIT (时间等待)状态，**TCP连接还没释放！**
	* 必须经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL 后， A 才进入到CLOSED 状态

> Q1:为什么要等2MSL（Maximum Segment Lifetime）
>
> 防止第四条B没有收到，经过2MSL后会收到B会重新发送的第三条
>
> Q2:关于确认号
>
> 注意见图！很重要
>
> Q3:为什么建立连接是三次握手，关闭连接确是四次挥手呢？
>
> 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
> 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次

### TCP vs UDP

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP  要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

### TCP怎样保证可靠传输

1. **校验和**： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

2. TCP 的接收端会丢弃重复的数据。 

3. **流量控制**：使用可变滑动窗口来进行控制

	![image-20210311220153152](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210311220153152.png)

4. **拥塞控制**：当网络拥塞时，减少数据的发送

5. **ARQ**：维护一个发送窗口，收到一个确认后发送窗口向前滑动

6. **超时重传**：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 谈谈拥塞控制的四个算法

https://blog.csdn.net/qq_41431406/article/details/97926927

1. **慢开始**

	假设当前发送方拥塞窗口cwnd的值为1，而发送窗口swnd等于拥塞窗口cwnd，因此发送方当前只能发送一个数据报文段（拥塞窗口cwnd的值是几，就能发送几个数据报文段），接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值乘2

	当前的拥塞窗口cwnd的值已经等于慢开始门限值，之后改用拥塞避免算法。

2. **拥塞避免**

	也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长

	理，16+1……直至到达24，假设24个报文段在传输过程中丢失4个，接收方只收到20个报文段，给发送方依次回复20个确认报文段，一段时间后，丢失的4个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改cwnd和ssthresh.并重新开始慢开始算法，如图所示

	![image-20210226223442720](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226223442720.png)、

	> 拥塞避免并非指能完全避免，只是比较不容易产生拥塞

3. **快重传**

	![image-20210226223607033](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226223607033.png)

4. **快恢复**

	![image-20210226223702254](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210226223702254.png)

## 数据链路层

> **封装成帧**，**透明传输**和**差错检测**

MAC地址+循环冗余校验

TCP校验和覆盖TCP首部和TCP数据，而IP首部中的校验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。TCP校验和、IP校验和的计算方法是基本一致的，除了计算的范围不同。

TCP的校验和是必需的，而UDP的校验和是可选的。TCP和UDP计算校验和时，都要加上一个12字节的伪首部。

## 物理层

### 任务

透明地传输比特流

### 信道复用技术

1. **频分复用(FDM)** ：所有用户在同样的时间占用不同的带宽资源。
2. **时分复用（TDM）** ：所有用户在不同的时间占用同样的频带宽度（分时不分频）。
3. **统计时分复用 (Statistic TDM)** ：改进的时分复用，能够明显提高信道的利用率。
4. **码分复用(CDM)** ： 用户使用经过特殊挑选的不同码型，因此各用户之间不会造成干扰。这种系统发送的信号有很强的抗干扰能力，其频谱类似于白噪声，不易被敌人发现。

# basic

## 三种IO

* **IO**

	一个进程的地址空间划分为 **用户空间（User space）** 和 **内核空间（Kernel space ）**

	我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。

	当应用程序发起 I/O 调用后，会经历两个步骤：

	1. 内核等待 I/O 设备准备好数据
	2. 内核将数据从内核空间拷贝到用户空间。

* **BIO（blocking IO）**

	同步阻塞IO

	应用程序发起 read 调用后，会一直阻塞，直到在内核把数据拷贝到用户空间

	<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210312165421869.png" alt="image-20210312165421869" style="zoom: 50%;" />

* **NIO(Non-blocking/New I/O)**

	同步非阻塞IO

	**IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗**

	通过选择器监听通道，非阻塞，处理完以后返回

	1. 轮询

		<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210312170644280.png" alt="image-20210312170644280" style="zoom:50%;" />

	2. IO多路复用

		准备好了再通知

		<img src="https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210312170701911.png" alt="image-20210312170701911" style="zoom:50%;" />

* **AIO**

	异步IO

	通过回调的方式

[漫话：如何给女朋友解释什么是Linux的五种IO模型？](https://mp.weixin.qq.com/s?__biz=Mzg3MjA4MTExMw==&mid=2247484746&idx=1&sn=c0a7f9129d780786cabfcac0a8aa6bb7&source=41&scene=21#wechat_redirect)

[京东数科二面：常见的 IO 模型有哪些？Java 中的 BIO、NIO、AIO 有啥区别？](https://www.cnblogs.com/javaguide/p/io.html)