# 并发

https://nyimac.gitee.io/2020/06/08/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/

## 什么是线程和进程？

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

参考OS扯

**线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；**

## 从JAVA角度谈谈进程和线程的关系

在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。

比如在JVM中，堆和方法区是进程共享的，PC、本地方法栈、虚拟机栈是线程私有的

> 补充：混合型、内核型、用户型进程
>
> 值得一提的是，我认为JAVA里的进程属于混合型进程。
>
> 1、证明java线程不是纯粹用户级线程：在java中起一堆线程，系统可以感知到。从java应用程序中的某个线程阻塞，是不会引起整个进程的阻塞，从这两点看，java线程绝不是纯粹的用户级线程。 （线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程）
>
> 2、再来，证明java线程不是纯粹内核级线程：这点比较直观，如果使用纯粹的内核级线程，那么有关线程的所有管理工作都是内核完成的，用户程序中没有管理线程的代码。显然，java线程库提供了大量的线程管理机制，因此java线程绝不是纯粹的内核级线程。 综上，java线程是混合型的线程模型，一般而言是通过lwp将用户级线程映射到内核线程中。
>
> https://blog.csdn.net/jinlong59421/article/details/105816973/
>
> https://blog.csdn.net/gdhgr/article/details/81945993

## 线程的六个状态

![image-20210309174527981](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309174527981.png)

![image-20210309174536575](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309174536575.png)

> 订正：原图中 wait到 runnable状态的转换中，`join`实际上是`Thread`类的方法，但这里写成了`Object`。

> 操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。

## 如何避免死锁

1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
2. **破坏请求与保持条件** ：一次性申请所有的资源。
3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

死锁避免：银行家算法（把锁看作资源）

## sleep和wait方法的异同

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- `wait()` 通常被用于线程间交互/通信，`sleep() `通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

## 什么用start方法而不用run

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

## wait()、notify()和notifyAll()方法为什么属于Object

* 原因一：Java中，任何对象都可以作为锁，既然wait是放弃对象锁，当然就要把wait定义在这个对象所属的类中。更通用一些，由于所有类都继承于Object，我们完全可以把wait方法定义在Object类中，这样，当我们定义一个新类，并需要以它的一个对象作为锁时，不需要我们再重新定义wait方法的实现，而是直接调用父类的wait(也就是Object的wait)，此处，用到了Java的继承。
* 原因二：有的人会说，既然是线程放弃对象锁，那也可以把wait定义在Thread类里面啊，新定义的线程继承于Thread类，也不需要重新定义wait方法的实现。然而，这样做有一个非常大的问题，一个线程完全可以持有很多锁，你一个线程放弃锁的时候，到底要放弃哪个锁？当然了，这种设计并不是不能实现，只是管理起来更加复杂。

综上所述，wait()、notify()和notifyAll()方法要定义在Object类中。

## synchronized底层原理

* **同步语句块**

	`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

	当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 对象监视器 `monitor` 的持有权。

	* 在执行`monitorenter`时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。

	* 在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

	```java
	public class SynchronizedDemo {
	    public void method() {
	        synchronized (this) {
	            System.out.println("synchronized 代码块");
	        }
	    }
	}
	```

	![image-20210309185734152](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309185734152.png)

* **同步方法**

	```java
	public class SynchronizedDemo2 {
	    public synchronized void method() {
	        System.out.println("synchronized 方法");
	    }
	}
	```

	`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

	![image-20210309185830392](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309185830392.png)

## monitor原理？

![image-20210315222705627](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210315222705627.png)

- 当线程执行到临界区代码时，如果使用了synchronized，会先查询synchronized中所指定的对象(obj)**是否绑定了Monitor**。

	- 如果**没有绑定**，则会先去去与Monitor绑定，并且将Owner设为当前线程。
	- 如果已经绑定，则会去查询该Monitor是否已经有了Owner
		- 如果没有，则Owner与将当前线程绑定
		- 如果有，则放入EntryList，进入阻塞状态(blocked)

- 当Monitor的Owner将临界区中代码执行完毕后，Owner便会被清空，此时EntryList中处于**阻塞**状态的线程会被**叫醒并竞争**，此时的竞争是**非公平的**

- **注意**：

	- 对象在使用了synchronized后与Monitor绑定时，会将对象头中的**Mark Word**置为Monitor指针。
	- 每个对象都会绑定一个**唯一的Monitor**，如果synchronized中所指定的对象(obj)**不同**，则会绑定**不同**的Monitor

- 锁对象调用wait方法（obj.wait），就会使当前线程进入WaitSet中，变为WAITING状态。

- 处于BLOCKED和WAITING状态的线程都为

	阻塞

	状态，CPU都不会分给他们时间片。但是有所区别：

	- BLOCKED状态的线程是在竞争对象时，发现Monitor的Owner已经是别的线程了，此时就会进入EntryList中，并处于BLOCKED状态
	- WAITING状态的线程是获得了对象的锁，但是自身因为某些原因需要进入阻塞状态时，锁对象调用了wait方法而进入了WaitSet中，处于WAITING状态

- BLOCKED状态的线程会在锁被释放的时候被唤醒，但是处于WAITING状态的线程只有被锁对象调用了notify方法(obj.notify/obj.notifyAll)，才会被唤醒。

## 锁优化

的状态从低到高依次为**无锁->偏向锁->轻量级锁->重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。

**自适应锁**：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。

**锁消除**：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。

**锁粗化**：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。

**偏向锁**：当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时都不需要CAS来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置-XX:+UseBiasedLocking开启偏向锁。

**轻量级锁**：JVM的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM将会使用CAS方式来尝试获取锁，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。

整个锁升级的过程非常复杂，我尽力去除一些无用的环节，简单来描述整个升级的机制。

![](https://pic4.zhimg.com/v2-a04036ccc8906893955e06a47e97d38b_r.jpg)

## （重要）谈谈synchronized锁升级的过程？

* 锁有四种状态，分别是**无锁、偏向锁、轻量锁、重量锁**。

* 为什么要有这四种状态

	* 第一因为避免线程状态转化造成的。OS中学到的多线程在临界区的方法一般是这里的重量级锁，即挂起等待，但是这种状态的转换需要用户、内核态的转变，十分耗费时间，其实有时候只需要等一下（自旋）就可以了，所以引入了偏向锁、轻量锁，还引入了自旋

* 需要掌握的是对象头

	![image-20210310213926968](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210310213926968.png)

	区别不同锁的重要标志是最后两位

* 无锁就不谈了

* 偏向锁

	初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，**线程并不会主动释放偏向锁**。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。

	释放锁偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。

	假设这时候锁是偏向锁，A在用，这时候B来了，先CAS，发现偏向锁的线程ID不是自己，就告诉JVM，等待一个全局安全点，这时候会检查A是否还是锁定状态，如果是就升级为偏向锁，如果不是就降级为无锁，然后B去竞争偏向锁

	A接受到消息之后，暂停当前的任务(实际上就是虚拟机暂停了A)，先将偏向锁取消，也就是CAS操作，把类头的那个字段清空。并且把类头上面，的锁的标志位，改为，我们接下来要说的`轻量级锁`。

* 轻量锁

	A和B线程都把对象的类头重的相关字段复制到自己的线程栈中。

	A线程通过CAS操作，把共享对象的类头重的相关字段的内容修改为自己新建的记录空间的地址。
	这个时候B就会尝试去获取轻量级锁

	然后B获取不到，会进入自旋状态也就是会进行多次CAS操作尝试。下面就会有两种情况。

	如果A线程通过，CAS操作，释放了锁，B线程随后获取到了，那么就会正常执行下去。

	如果B线程尝试了多次之后，还没得到，虚拟机就暂停A，然后会把锁的标志位改成重量级锁，并

	把线程B的状态信息写入到Monitor的阻塞队列中，线程B进入到阻塞状态，以及A的信息也写入monitor，然后恢复A的执行。

* 重量锁

	一看最后两位，是重量锁，那不等了，直接monitor的等待队列挂起

**从上面的情况可以看到，升级的过程，总是要暂停那个正在执行的线程，然后进行锁升级，升级完成后，恢复执行。那么如果锁等级可逆。那么可能会存在锁升级过多次出现的情况，（可能对大部分情况来说）对性能消耗大。所以JVM实现的这个锁升级是不可逆的。也就是，例如不可以从重量级锁，回到之前的锁。**

> 参考
>
> [Java6及以上版本对synchronized的优化](https://www.cnblogs.com/wuqinglong/p/9945618.html)
>
> [深度分析：锁升级过程和锁状态，看完这篇你就懂了！](https://www.cnblogs.com/lwh1019/p/13093581.html)
>
> https://www.zhihu.com/question/384014892/answer/1117940282
>
> [理解JVM对synchronized进行的优化](https://blog.csdn.net/u011580175/article/details/101495253/)
>
> [synchronized的实现原理及锁优化](https://www.cnblogs.com/xdyixia/p/9364247.html)

## synchronized和ReentrantLock

* **synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

	`synchronized` 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 `synchronized` 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。`ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

* **可中断**

	如果某个线程处于阻塞状态，可以调用其interrupt方法让其停止阻塞，获得锁失败

* **可以设置超时时间**

	tryLock

* **可以设置为公平锁 (先到先得)**

* **支持多个条件变量( 具有多个waitset)**

	ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持**多个**条件变量的，这就好比

	- synchronized 是那些不满足条件的线程都在一间休息室等消息
	- 而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤 醒
	- await 前需要**获得锁**
	- await 执行后，会释放锁，进入 conditionObject 等待
	- await 的线程被唤醒（或打断、或超时）取重新竞争 lock 锁
	- 竞争 lock 锁成功后，从 await 后继续执

## ThreadLocal原理

在每个线程内部都有一个名为threadLocals的成员变量，该变量的类型为HashMap，其中**key为我们定义的ThreadLocal变量的this引用，value则为我们使用set方法设置的值**。每个线程的本地变量存放在线程自己的内存变量threadLocals中

只有当前线程**第一次调用ThreadLocal的set或者get方法时才会创建threadLocals**（inheritableThreadLocals也是一样）。其实每个线程的本地变量不是存放在ThreadLocal实例里面，而是存放在调用线程的threadLocals变量里面

## ThreadLocal为什么会内存泄漏

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

```java
      static class Entry extends WeakReference<ThreadLocal<?>> {
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }Copy to clipboardErrorCopied
```

## 线程池创建方式

1. **构造函数**

	![image-20210310000710735](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210310000710735.png)

2. **通过 Executor 框架的工具类 Executors 来实现**

	- **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
		- 都用到LinkedBlockingQueue
	- **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量（maximumPoolSize）为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。
		- cached：SynchronousQueue，长度是0
		- scheduled：DelayedWorkQueue，长度无上限

https://zhuanlan.zhihu.com/p/112527671

## 线程池参数

**`ThreadPoolExecutor` 3 个最重要的参数：**

- `corePoolSize` : 核心线程数线程数定义了最小可以同时运行的线程数量。
- `maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- `workQueue`: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数:

1. `keepAliveTime`:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. `unit` : `keepAliveTime` 参数的时间单位。
3. `threadFactory` :executor 创建新线程的时候会用到。
4. `handler` :饱和策略。关于饱和策略下面单独介绍一下。

## 什么是饱和策略？

**`ThreadPoolExecutor` 饱和策略定义:**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，`ThreadPoolTaskExecutor` 定义一些策略:

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

## 线程池大小变化

![image-20210309234004528](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309234004528.png)

**新提交一个任务时的处理流程很明显：**

1. 如果当前线程池的线程数还没有达到基本大小(poolSize < corePoolSize)，**无论是否有空闲的线程新增一个线程处理新提交的任务；**

2. 如果当前线程池的线程数大于或等于基本大小(poolSize >= corePoolSize) **且任务队列未满时**，就将新提交的任务提交到阻塞队列排队，等候处理workQueue.offer(command)；

3. 如果当前线程池的线程数大于或等于基本大小(poolSize >= corePoolSize) **且任务队列满时**；

	* 当前poolSize<maximumPoolSize，那么就**新增线程**来处理任务；

	* 当前poolSize=maximumPoolSize，那么意味着线程池的处理能力已经达到了极限，此时要拒绝新增加的任务。至于如何拒绝处理新增的任务，取决于线程池的饱和策RejectedExecutionHandler。

## 线程池示例

```java
    private static final int CORE_POOL_SIZE =5 ;
    private static final int MAX_POOL_SIZE = 10;
    private static final int QUEUE_CAPACITY = 30;
    private static final Long KEEP_ALIVE_TIME = 1L;
    public static void main(String[] args) {

        //使用阿里巴巴推荐的创建线程池的方式
        //通过ThreadPoolExecutor构造函数自定义参数创建
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                CORE_POOL_SIZE,
                MAX_POOL_SIZE,
                KEEP_ALIVE_TIME,
                TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(QUEUE_CAPACITY),
                new ThreadPoolExecutor.CallerRunsPolicy());
//        ExecutorService executor = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 15; i++) {
            executor.execute(new MyRunnable(""+i));
        }
        executor.shutdown();
    }
```

![image-20210309233751449](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309233751449.png)

修改

```java
    private static final int CORE_POOL_SIZE =5 ;
    private static final int MAX_POOL_SIZE = 10;
    private static final int QUEUE_CAPACITY = 5;
    private static final Long KEEP_ALIVE_TIME = 1L;
    public static void main(String[] args) {

        //使用阿里巴巴推荐的创建线程池的方式
        //通过ThreadPoolExecutor构造函数自定义参数创建
        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                CORE_POOL_SIZE,
                MAX_POOL_SIZE,
                KEEP_ALIVE_TIME,
                TimeUnit.SECONDS,
                new ArrayBlockingQueue<>(QUEUE_CAPACITY),
                new ThreadPoolExecutor.CallerRunsPolicy());
//        ExecutorService executor = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 11; i++) {
            executor.execute(new MyRunnable(""+i));
        }
        executor.shutdown();
    }
```



![image-20210309233911524](https://cyzblog.oss-cn-beijing.aliyuncs.com/image-20210309233911524.png)

分析：第11个任务过来，核心线程已满，队列已满，所以会创建新线程

## JMM

JMM 即 Java Memory Model，它定义了**主存（共享内存）、工作内存（线程私有）**抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。

**JMM体现在以下几个方面**

- 原子性 - 保证指令不会受到线程上下文切换的影响
- 可见性 - 保证指令不会受 cpu 缓存的影响
	- volatile，直接写入主存
- 有序性 - 保证指令不会受 cpu 指令并行优化的影响
	- 防止指令重排

## 进程通信

(1)  管道(PIPE) 
 (2)  命名管道(FIFO) 
 (3)  信号量(Semphore) 
 (4)  消息队列(MessageQueue) 
 (5)  共享内存(SharedMemory) 
 (6)  Socket



## happens-before

　　1. 单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。

　　首先是单线程的 HB ，前面的操作产生的结果必须对后面的操作可见。而不是前面的操作必须先于后面的操作执行，比如按照  as-if-serial 语义，没有数据依赖的两条指令是可以进行重排序的。而这种情况对于 HB  原则来说，因为两条指令都没有产生对方需要的结果，而不需要对对方可见，及时执行顺序被调转也是符合 HB 原则的。

　　2. 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。

　　个人理解强调的是解锁操作在多线程环境的可见性。一个线程进行了解锁操作，对于晚于该操作的加锁操作必须能够及时感应到锁的状态变化。解锁操作的结果对后面的加锁操作一定是可见的，无论两个是否在一个线程。

　　3. volatile的happen-before原则： 对一个volatile变量的写操作happen-before对此变量的任意操作。

　　对 volatile 变量的写操作的结果对于发生于其后的任何操作的结果都是可见的。x86 架构下volatile 通过内存屏障和缓存一致性协议实现了变量在多核心之间的一致性。

　　4. happen-before的传递性原则：  如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。

　　HB 可以说是两项操作之间的**偏序关系**，满足偏序关系的各项性质，我们都知道偏序关系中有一条很重要的性质：传递性，所以Happens-Before也满足传递性。这个性质非常重要，通过这个性质可以推导出两个没有直接联系的操作之间存在Happens-Before关系

　　5. 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。

　　start 放法与其它方法可能并没有数据依赖关系，但是显而易见的，为了程序的正确性，我们必须做到这一点。start 方法造成的函数副作用必须对其它方法可见。

## AQS

[从ReentrantLock的实现看AQS的原理及应用](https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html)

[Java 并发高频面试题：聊聊你对 AQS 的理解？](https://zhuanlan.zhihu.com/p/86072774)